"""
src/training/conservative_augmentation_tester.py

ë³´ìˆ˜ì  ì¦ê°• í…ŒìŠ¤í„° - ê¸°ì¡´ ì„±ëŠ¥ ìœ ì§€í•˜ë©° ì ì§„ì  ê°œì„ 
Conservative augmentation tester for safe progressive enhancement
"""

import sys
import os
from pathlib import Path

# ğŸ”§ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì • (í•­ìƒ ì²« ë²ˆì§¸ë¡œ)
project_root = str(Path(__file__).parent.parent.parent)
sys.path.insert(0, project_root)
os.chdir(project_root)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
import json
import fire
from icecream import ic
import copy
from datetime import datetime

from src.utils.config_utils import load_config, normalize_config_structure
from src.data.csv_dataset import CSVDocumentDataset
from src.data.augmentation import get_configurable_transforms, get_valid_transforms
from src.models.model import create_model
from src.trainer.wandb_trainer import WandBTrainer
from src.trainer.trainer import Trainer
from src.inference.predictor import predict_from_checkpoint, save_predictions


class ConservativeAugmentationTester:
    """ê¸°ì¡´ ì„±ëŠ¥ ìœ ì§€í•˜ë©° ì•ˆì „í•˜ê²Œ ì¦ê°• í…ŒìŠ¤íŠ¸í•˜ëŠ” ì‹œìŠ¤í…œ"""
    
    def __init__(self, config_path: str = "configs/config.yaml", 
                 baseline_checkpoint: str = None):
        """
        ì´ˆê¸°í™”
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
            baseline_checkpoint: ê¸°ì¤€ì ì´ ë˜ëŠ” ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
        """
        self.config = load_config(config_path)
        self.config = normalize_config_structure(self.config)
        self.baseline_checkpoint = baseline_checkpoint
        self.setup_paths()
        ic("ë³´ìˆ˜ì  ì¦ê°• í…ŒìŠ¤í„° ì´ˆê¸°í™” ì™„ë£Œ")
        
    def setup_paths(self):
        """ê²½ë¡œ ì„¤ì •"""
        self.output_dir = Path('outputs/conservative_augmentation_test')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ì‹¤í—˜ ê²°ê³¼ ì €ì¥ìš© ë””ë ‰í† ë¦¬
        self.experiment_dir = self.output_dir / f"experiment_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.experiment_dir.mkdir(parents=True, exist_ok=True)
        
        ic(f"ì‹¤í—˜ ê²°ê³¼ ì €ì¥: {self.experiment_dir}")
    
    def create_progressive_augmentation_configs(self) -> List[Dict]:
        """ì ì§„ì  ì¦ê°• ì„¤ì •ë“¤ ìƒì„± (Gemini ì „ëµ ê¸°ë°˜)"""
        ic("ì ì§„ì  ì¦ê°• ì„¤ì • ìƒì„±")
        
        # ê¸°ë³¸ ì„¤ì • ë³µì‚¬
        base_config = copy.deepcopy(self.config)
        
        # Geminiì˜ ê¶Œì¥ì‚¬í•­ ê¸°ë°˜ ì ì§„ì  ì„¤ì •
        progressive_configs = []
        
        # Phase 0: ê¸°ì¤€ì  (ê¸°ì¡´ ì„¤ì •)
        baseline_config = copy.deepcopy(base_config)
        baseline_config['experiment_name'] = 'phase_0_baseline'
        baseline_config['description'] = 'ê¸°ì¤€ì  - ê¸°ì¡´ ì„¤ì •'
        baseline_config['data']['augmentation'] = {
            'strategy': 'basic',
            'intensity': 0.3
        }
        progressive_configs.append(baseline_config)
        
        # Phase 1: íšŒì „ ë„ì… (Critical Priority)
        phase1_config = copy.deepcopy(base_config)
        phase1_config['experiment_name'] = 'phase_1_rotation_mild'
        phase1_config['description'] = 'Phase 1: íšŒì „ ì¦ê°• ë„ì… (Â±10Â°)'
        phase1_config['data']['augmentation'] = {
            'strategy': 'robust',
            'intensity': 0.5,
            'geometric': {
                'enabled': True,
                'intensity': 0.3,
                'rotation_limit': 10,  # Â±10Â° (Gemini ê¶Œì¥)
                'perspective_scale': [0.02, 0.08]
            },
            'lighting': {
                'enabled': True,
                'intensity': 0.4,
                'brightness_contrast_limit': 0.2,
                'gamma_range': [80, 120]
            },
            'quality': {
                'enabled': False  # ì•„ì§ ë¸”ëŸ¬ëŠ” ì¶”ê°€í•˜ì§€ ì•ŠìŒ
            }
        }
        progressive_configs.append(phase1_config)
        
        # Phase 2: íšŒì „ + ì¡°ëª… ê°•í™”
        phase2_config = copy.deepcopy(base_config)
        phase2_config['experiment_name'] = 'phase_2_rotation_lighting'
        phase2_config['description'] = 'Phase 2: íšŒì „ + ì¡°ëª… ì¦ê°• (Â±15Â°, ê³¼ë…¸ì¶œ ì‹œë®¬ë ˆì´ì…˜)'
        phase2_config['data']['augmentation'] = {
            'strategy': 'robust',
            'intensity': 0.6,
            'geometric': {
                'enabled': True,
                'intensity': 0.5,
                'rotation_limit': 15,  # Â±15Â° í™•ì¥
                'perspective_scale': [0.03, 0.10]
            },
            'lighting': {
                'enabled': True,
                'intensity': 0.6,
                'brightness_contrast_limit': 0.3,  # ê³¼ë…¸ì¶œ ì‹œë®¬ë ˆì´ì…˜ ê°•í™”
                'gamma_range': [70, 130],
                'overexposure_probability': 0.3  # ê³¼ë…¸ì¶œ ë¹ˆë„ ì¦ê°€
            },
            'quality': {
                'enabled': True,
                'intensity': 0.3,  # ì•½í•œ ë¸”ëŸ¬ë§Œ
                'blur_probability': 0.2
            }
        }
        progressive_configs.append(phase2_config)
        
        # Phase 3: íƒ€ê²Ÿ ê°•ë„ (Â±25Â°)
        phase3_config = copy.deepcopy(base_config)
        phase3_config['experiment_name'] = 'phase_3_target_intensity'
        phase3_config['description'] = 'Phase 3: íƒ€ê²Ÿ ê°•ë„ (Â±25Â°, í’€ ì¡°ëª… ì¦ê°•)'
        phase3_config['data']['augmentation'] = {
            'strategy': 'robust',
            'intensity': 0.7,
            'geometric': {
                'enabled': True,
                'intensity': 0.7,
                'rotation_limit': 25,  # Gemini Phase 2 ìˆ˜ì¤€
                'perspective_scale': [0.05, 0.15]
            },
            'lighting': {
                'enabled': True,
                'intensity': 0.8,
                'brightness_contrast_limit': 0.4,  # [0.8, 1.8] ë²”ìœ„
                'gamma_range': [70, 130],
                'overexposure_probability': 0.5  # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì¤€
            },
            'quality': {
                'enabled': True,
                'intensity': 0.5,
                'blur_probability': 0.4,
                'noise_probability': 0.3
            }
        }
        progressive_configs.append(phase3_config)
        
        # Phase 4: ìµœëŒ€ ê°•ë„ (Â±45Â° - Gemini ìµœì¢… ê¶Œì¥)
        phase4_config = copy.deepcopy(base_config)
        phase4_config['experiment_name'] = 'phase_4_maximum_robustness'
        phase4_config['description'] = 'Phase 4: ìµœëŒ€ robustness (Â±45Â°)'
        phase4_config['data']['augmentation'] = {
            'strategy': 'robust',
            'intensity': 0.8,
            'geometric': {
                'enabled': True,
                'intensity': 0.9,
                'rotation_limit': 45,  # Gemini ìµœì¢… ê¶Œì¥
                'perspective_scale': [0.05, 0.15]
            },
            'lighting': {
                'enabled': True,
                'intensity': 0.8,
                'brightness_contrast_limit': 0.5,  # ìµœëŒ€ ê°•ë„
                'gamma_range': [60, 140],
                'overexposure_probability': 0.6
            },
            'quality': {
                'enabled': True,
                'intensity': 0.6,
                'blur_probability': 0.5,
                'noise_probability': 0.4
            }
        }
        progressive_configs.append(phase4_config)
        
        ic(f"ìƒì„±ëœ ì¦ê°• ì„¤ì •: {len(progressive_configs)}ê°œ ë‹¨ê³„")
        return progressive_configs
    
    def create_augmentation_transforms(self, aug_config: Dict):
        """ì¦ê°• ì„¤ì •ìœ¼ë¡œë¶€í„° transform ìƒì„±"""
        data_config = self.config['data']
        img_size = data_config['image_size']
        mean = data_config['mean']
        std = data_config['std']
        
        # ì„¤ì •ëœ ì¦ê°• ì „ëµì— ë”°ë¼ transform ìƒì„±
        if aug_config.get('strategy') == 'robust':
            return get_configurable_transforms(img_size, img_size, mean, std, aug_config)
        else:
            # ê¸°ë³¸ ì¦ê°•ìœ¼ë¡œ í´ë°±
            from src.data.augmentation import get_train_transforms
            return get_train_transforms(img_size, img_size, mean, std)
    
    def run_quick_validation(self, config: Dict, epochs: int = 3) -> Dict:
        """ë¹ ë¥¸ ê²€ì¦ í›ˆë ¨ (ì„±ëŠ¥ ë³€í™” í™•ì¸ìš©)"""
        ic(f"ë¹ ë¥¸ ê²€ì¦ ì‹œì‘: {config['experiment_name']}")
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        device = torch.device(self.config['device'] if torch.cuda.is_available() else 'cpu')
        
        # ë°ì´í„° ì¤€ë¹„
        augmentation_config = config['data'].get('augmentation', {})
        
        # Transform ìƒì„±
        train_transforms = self.create_augmentation_transforms(augmentation_config)
        valid_transforms = get_valid_transforms(
            height=self.config['data']['image_size'],
            width=self.config['data']['image_size'],
            mean=self.config['data']['mean'],
            std=self.config['data']['std']
        )
        
        # ë°ì´í„°ì…‹ ìƒì„±
        train_dataset = CSVDocumentDataset(
            root_dir=self.config['data']['root_dir'],
            csv_file=self.config['data']['csv_file'],
            meta_file=self.config['data']['meta_file'],
            split='train',
            transform=train_transforms,
            val_size=self.config['data']['val_size'],
            seed=self.config['seed']
        )
        
        val_dataset = CSVDocumentDataset(
            root_dir=self.config['data']['root_dir'],
            csv_file=self.config['data']['csv_file'],
            meta_file=self.config['data']['meta_file'],
            split='val',
            transform=valid_transforms,
            val_size=self.config['data']['val_size'],
            seed=self.config['seed']
        )
        
        # ë°ì´í„° ë¡œë” ìƒì„±
        train_loader = DataLoader(
            train_dataset,
            batch_size=self.config['train']['batch_size'],
            shuffle=True,
            num_workers=self.config['data']['num_workers'],
            pin_memory=True if device.type == 'cuda' else False
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.config['train']['batch_size'],
            shuffle=False,
            num_workers=self.config['data']['num_workers'],
            pin_memory=True if device.type == 'cuda' else False
        )
        
        # ëª¨ë¸ ìƒì„± (ì•ˆì „í•œ config ì ‘ê·¼)
        num_classes = len(train_dataset.classes)
        model_config = self.config.get('model', {})
        model_name = model_config.get('name', 'resnet50')
        pretrained = model_config.get('pretrained', True)
        
        model = create_model(
            model_name=model_name,
            num_classes=num_classes,
            pretrained=pretrained
        ).to(device)
        
        # ê¸°ì¤€ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        if self.baseline_checkpoint and Path(self.baseline_checkpoint).exists():
            ic(f"ê¸°ì¤€ ëª¨ë¸ ë¡œë“œ: {self.baseline_checkpoint}")
            checkpoint = torch.load(self.baseline_checkpoint, map_location=device)
            model.load_state_dict(checkpoint)
        
        # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬
        optimizer_config = self.config['optimizer']
        if optimizer_config['name'] == 'AdamW':
            optimizer = optim.AdamW(
                model.parameters(),
                lr=optimizer_config['learning_rate'],
                weight_decay=optimizer_config['weight_decay']
            )
        elif optimizer_config['name'] == 'Adam':
            optimizer = optim.Adam(
                model.parameters(),
                lr=optimizer_config['learning_rate'],
                weight_decay=optimizer_config['weight_decay']
            )
        else:
            optimizer = optim.SGD(
                model.parameters(),
                lr=optimizer_config['learning_rate'],
                weight_decay=optimizer_config['weight_decay']
            )
        
        # ì†ì‹¤ í•¨ìˆ˜
        loss_fn = nn.CrossEntropyLoss()
        
        # ë¹ ë¥¸ í›ˆë ¨ì„ ìœ„í•œ ì„¤ì • ìˆ˜ì •
        quick_config = copy.deepcopy(config)
        quick_config['train']['epochs'] = epochs
        quick_config['wandb']['enabled'] = False  # WandB ë¡œê¹… ë¹„í™œì„±í™”
        
        # íŠ¸ë ˆì´ë„ˆ ìƒì„± (WandB ì—†ëŠ” ê¸°ë³¸ íŠ¸ë ˆì´ë„ˆ)
        trainer = Trainer(model, optimizer, None, loss_fn, train_loader, val_loader, device, quick_config)
        
        # í›ˆë ¨ ì‹¤í–‰
        trainer.train()
        
        # ê²°ê³¼ ìˆ˜ì§‘
        if trainer.history:
            final_results = trainer.history[-1]
            results = {
                'experiment_name': config['experiment_name'],
                'final_val_accuracy': final_results.get('val_acc', 0),
                'final_val_f1': final_results.get('val_f1', 0),
                'final_train_loss': final_results.get('train_loss', 0),
                'final_val_loss': final_results.get('val_loss', 0),
                'epochs_completed': len(trainer.history),
                'augmentation_config': augmentation_config
            }
        else:
            results = {
                'experiment_name': config['experiment_name'],
                'error': 'No training history available',
                'augmentation_config': augmentation_config
            }
        
        # ëª¨ë¸ ì €ì¥
        model_path = self.experiment_dir / f"{config['experiment_name']}_model.pth"
        torch.save(model.state_dict(), model_path)
        results['model_path'] = str(model_path)
        
        ic(f"ë¹ ë¥¸ ê²€ì¦ ì™„ë£Œ: {config['experiment_name']}")
        ic(f"Val F1: {results.get('final_val_f1', 0):.4f}")
        
        return results
    
    def compare_with_baseline(self, results: List[Dict]) -> Dict:
        """ê¸°ì¤€ì  ëŒ€ë¹„ ì„±ëŠ¥ ë¹„êµ"""
        ic("ê¸°ì¤€ì  ëŒ€ë¹„ ì„±ëŠ¥ ë¹„êµ")
        
        baseline_result = None
        for result in results:
            if 'baseline' in result['experiment_name']:
                baseline_result = result
                break
        
        if not baseline_result:
            ic("ê¸°ì¤€ì  ê²°ê³¼ ì—†ìŒ")
            return {}
        
        baseline_f1 = baseline_result.get('final_val_f1', 0)
        baseline_acc = baseline_result.get('final_val_accuracy', 0)
        
        comparison = {
            'baseline_performance': {
                'f1': baseline_f1,
                'accuracy': baseline_acc
            },
            'phase_comparisons': []
        }
        
        for result in results:
            if result['experiment_name'] == baseline_result['experiment_name']:
                continue
            
            current_f1 = result.get('final_val_f1', 0)
            current_acc = result.get('final_val_accuracy', 0)
            
            f1_improvement = current_f1 - baseline_f1
            acc_improvement = current_acc - baseline_acc
            
            phase_comparison = {
                'experiment_name': result['experiment_name'],
                'f1_score': current_f1,
                'accuracy': current_acc,
                'f1_improvement': f1_improvement,
                'f1_improvement_percent': (f1_improvement / baseline_f1 * 100) if baseline_f1 > 0 else 0,
                'accuracy_improvement': acc_improvement,
                'performance_safe': f1_improvement >= -0.05,  # 5% ì´í•˜ ì„±ëŠ¥ ì €í•˜ë§Œ í—ˆìš©
                'recommended_for_full_training': f1_improvement > 0.02 and f1_improvement >= -0.02
            }
            
            comparison['phase_comparisons'].append(phase_comparison)
        
        # ìµœê³  ì„±ëŠ¥ ë‹¨ê³„ ì‹ë³„
        best_phase = max(comparison['phase_comparisons'], 
                        key=lambda x: x['f1_score']) if comparison['phase_comparisons'] else None
        
        if best_phase:
            comparison['best_phase'] = best_phase['experiment_name']
            comparison['best_f1_improvement'] = best_phase['f1_improvement']
        
        return comparison
    
    def generate_recommendations(self, comparison: Dict) -> Dict:
        """ë¹„êµ ê²°ê³¼ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        ic("ê¶Œì¥ì‚¬í•­ ìƒì„±")
        
        recommendations = {
            'safe_phases': [],
            'promising_phases': [],
            'risky_phases': [],
            'next_actions': [],
            'full_training_candidate': None
        }
        
        if 'phase_comparisons' not in comparison:
            return recommendations
        
        for phase in comparison['phase_comparisons']:
            if phase['performance_safe']:
                recommendations['safe_phases'].append(phase['experiment_name'])
                
                if phase['recommended_for_full_training']:
                    recommendations['promising_phases'].append(phase['experiment_name'])
            else:
                recommendations['risky_phases'].append(phase['experiment_name'])
        
        # í’€ í›ˆë ¨ í›„ë³´ ì„ ì •
        promising_phases = [p for p in comparison['phase_comparisons'] 
                          if p['recommended_for_full_training']]
        
        if promising_phases:
            best_promising = max(promising_phases, key=lambda x: x['f1_improvement'])
            recommendations['full_training_candidate'] = best_promising['experiment_name']
            
            recommendations['next_actions'].extend([
                f"'{best_promising['experiment_name']}' ì„¤ì •ìœ¼ë¡œ í’€ í›ˆë ¨ ì‹¤í–‰ ê¶Œì¥",
                f"ì˜ˆìƒ F1 ê°œì„ : {best_promising['f1_improvement']:.4f} ({best_promising['f1_improvement_percent']:.1f}%)",
                "ê¸°ì¡´ 79% ì„±ëŠ¥ ëŒ€ë¹„ ì•ˆì „í•œ ê°œì„  ì˜ˆìƒ"
            ])
        else:
            recommendations['next_actions'].extend([
                "í˜„ì¬ ë‹¨ê³„ì—ì„œëŠ” í° ê°œì„ ì´ ì–´ë ¤ì›€",
                "ë” ì„¸ë°€í•œ ì¦ê°• íŠœë‹ ë˜ëŠ” ë‹¤ë¥¸ ì ‘ê·¼ë²• í•„ìš”",
                "ê¸°ì¡´ ì„¤ì • ìœ ì§€ë¥¼ ê¶Œì¥"
            ])
        
        return recommendations
    
    def save_experiment_results(self, results: List[Dict], comparison: Dict, 
                              recommendations: Dict):
        """ì‹¤í—˜ ê²°ê³¼ ì €ì¥"""
        ic("ì‹¤í—˜ ê²°ê³¼ ì €ì¥")
        
        # ì „ì²´ ê²°ê³¼ ì €ì¥
        all_results = {
            'timestamp': datetime.now().isoformat(),
            'baseline_checkpoint': self.baseline_checkpoint,
            'phase_results': results,
            'performance_comparison': comparison,
            'recommendations': recommendations
        }
        
        with open(self.experiment_dir / 'experiment_results.json', 'w', encoding='utf-8') as f:
            json.dump(all_results, f, indent=2, ensure_ascii=False)
        
        # ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
        report_path = self.experiment_dir / 'experiment_summary.txt'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# ë³´ìˆ˜ì  ì¦ê°• í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë³´ê³ ì„œ\n")
            f.write("=" * 50 + "\n\n")
            
            # ê¸°ì¤€ì  ì„±ëŠ¥
            if 'baseline_performance' in comparison:
                baseline = comparison['baseline_performance']
                f.write(f"## ê¸°ì¤€ì  ì„±ëŠ¥\n")
                f.write(f"- F1 Score: {baseline['f1']:.4f}\n")
                f.write(f"- Accuracy: {baseline['accuracy']:.4f}\n\n")
            
            # ë‹¨ê³„ë³„ ê²°ê³¼
            f.write("## ë‹¨ê³„ë³„ ê²°ê³¼\n")
            for phase in comparison.get('phase_comparisons', []):
                f.write(f"### {phase['experiment_name']}\n")
                f.write(f"- F1 Score: {phase['f1_score']:.4f} (ê°œì„ : {phase['f1_improvement']:+.4f})\n")
                f.write(f"- Accuracy: {phase['accuracy']:.4f} (ê°œì„ : {phase['accuracy_improvement']:+.4f})\n")
                f.write(f"- ì•ˆì „ì„±: {'âœ…' if phase['performance_safe'] else 'âŒ'}\n")
                f.write(f"- í’€ í›ˆë ¨ ê¶Œì¥: {'âœ…' if phase['recommended_for_full_training'] else 'âŒ'}\n\n")
            
            # ê¶Œì¥ì‚¬í•­
            f.write("## ê¶Œì¥ì‚¬í•­\n")
            for action in recommendations.get('next_actions', []):
                f.write(f"- {action}\n")
            
            if recommendations.get('full_training_candidate'):
                f.write(f"\n**ì¶”ì²œ ì„¤ì •**: {recommendations['full_training_candidate']}\n")
        
        ic(f"ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {self.experiment_dir}")
        return str(report_path)
    
    def run_conservative_augmentation_test(self, baseline_checkpoint: str = None, 
                                         quick_epochs: int = 3):
        """ë³´ìˆ˜ì  ì¦ê°• í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        ic("ë³´ìˆ˜ì  ì¦ê°• í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        if baseline_checkpoint:
            self.baseline_checkpoint = baseline_checkpoint
        
        # 1. ì ì§„ì  ì¦ê°• ì„¤ì • ìƒì„±
        progressive_configs = self.create_progressive_augmentation_configs()
        
        # 2. ê° ë‹¨ê³„ë³„ ë¹ ë¥¸ ê²€ì¦
        results = []
        for config in progressive_configs:
            try:
                result = self.run_quick_validation(config, epochs=quick_epochs)
                results.append(result)
                
                # ì¤‘ê°„ ê²°ê³¼ ì¶œë ¥
                ic(f"Phase: {config['experiment_name']}")
                ic(f"Val F1: {result.get('final_val_f1', 0):.4f}")
                
            except Exception as e:
                ic(f"ì˜¤ë¥˜ ë°œìƒ: {config['experiment_name']} - {e}")
                results.append({
                    'experiment_name': config['experiment_name'],
                    'error': str(e)
                })
        
        # 3. ì„±ëŠ¥ ë¹„êµ
        comparison = self.compare_with_baseline(results)
        
        # 4. ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = self.generate_recommendations(comparison)
        
        # 5. ê²°ê³¼ ì €ì¥
        summary_path = self.save_experiment_results(results, comparison, recommendations)
        
        ic("ë³´ìˆ˜ì  ì¦ê°• í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        ic(f"ê²°ê³¼ ë³´ê³ ì„œ: {summary_path}")
        
        return {
            'results': results,
            'comparison': comparison,
            'recommendations': recommendations,
            'summary_report': summary_path,
            'experiment_dir': str(self.experiment_dir)
        }


def main():
    """Fire CLI ì¸í„°í˜ì´ìŠ¤"""
    fire.Fire(ConservativeAugmentationTester)


if __name__ == "__main__":
    main()