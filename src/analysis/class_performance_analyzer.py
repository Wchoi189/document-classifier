"""
src/analysis/class_performance_analyzer.py

í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„ ë° ì·¨ì•½ì  ì‹ë³„ ë„êµ¬
Class performance analyzer to identify vulnerable classes and corruption sensitivities
"""
import sys
import os
from pathlib import Path

# ğŸ”§ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì • (í•­ìƒ ì²« ë²ˆì§¸ë¡œ)
project_root = str(Path(__file__).parent.parent.parent)
sys.path.insert(0, project_root)
os.chdir(project_root)

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
import json
import fire
from icecream import ic
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib as mpl
from matplotlib.figure import Figure
mpl.rcParams['font.family'] = 'NanumGothic'
mpl.rcParams['axes.unicode_minus'] = False
sns.set_theme(style="whitegrid", font="NanumGothic", font_scale=1.1, rc={'axes.unicode_minus': False}
)
from collections import defaultdict, Counter

from src.utils.config_utils import load_config, safe_classification_report_access


class ClassPerformanceAnalyzer:
    """í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë° corruption ì·¨ì•½ì  ë¶„ì„ê¸°"""
    
    def __init__(self, config_path: str = "configs/config.yaml"):
        """
        ì´ˆê¸°í™”
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.config = load_config(config_path)
        self.setup_paths()
        self.load_class_mappings()
        ic("í´ë˜ìŠ¤ ì„±ëŠ¥ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
    def setup_paths(self):
        """ê²½ë¡œ ì„¤ì •"""
        self.output_dir = Path('outputs/class_performance_analysis')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Corruption ë¶„ì„ ê²°ê³¼ ê²½ë¡œ
        self.corruption_dir = Path('outputs/corruption_analysis')
        
        ic(f"ê²°ê³¼ ì €ì¥: {self.output_dir}")
        ic(f"Corruption ë¶„ì„ ê²½ë¡œ: {self.corruption_dir}")
    
    def load_class_mappings(self):
        """í´ë˜ìŠ¤ ë§¤í•‘ ì •ë³´ ë¡œë“œ"""
        data_config = self.config.get('data', {})
        meta_file = data_config.get('meta_file', 'data/dataset/meta.csv')
        
        if Path(meta_file).exists():
            self.meta_df = pd.read_csv(meta_file)
            self.class_names = dict(zip(self.meta_df['target'], self.meta_df['class_name']))
            self.num_classes = len(self.class_names)
            ic(f"í´ë˜ìŠ¤ ì •ë³´ ë¡œë“œ: {self.num_classes}ê°œ í´ë˜ìŠ¤")
        else:
            ic(f"ë©”íƒ€ íŒŒì¼ ì—†ìŒ, ê¸°ë³¸ í´ë˜ìŠ¤ëª… ì‚¬ìš©: {meta_file}")
            self.num_classes = 17
            self.class_names = {i: f"class_{i}" for i in range(self.num_classes)}
    
    def load_prediction_results(self, predictions_csv: str, ground_truth_csv: Optional[str] = None) -> pd.DataFrame:
        """ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        ic(f"ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ: {predictions_csv}")
        
        # ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ
        df_pred = pd.read_csv(predictions_csv)
        
        # ì •ë‹µ ë°ì´í„°ê°€ ì œê³µëœ ê²½ìš°
        if ground_truth_csv and Path(ground_truth_csv).exists():
            ic(f"ì •ë‹µ ë°ì´í„° ë¡œë“œ: {ground_truth_csv}")
            df_true = pd.read_csv(ground_truth_csv)
            
            # íŒŒì¼ëª…ìœ¼ë¡œ ì¡°ì¸
            df_pred['join_key'] = df_pred['filename'].str.replace(r'\.(jpg|jpeg|png)$', '', regex=True)
            df_true['join_key'] = df_true['ID'].str.replace(r'\.(jpg|jpeg|png)$', '', regex=True)
            
            df_merged = pd.merge(df_pred, df_true, on='join_key', how='inner')
            
            if df_merged.empty:
                raise ValueError("ì˜ˆì¸¡ ê²°ê³¼ì™€ ì •ë‹µ ë°ì´í„° ê°„ ë§¤ì¹­ ì‹¤íŒ¨")
            
            ic(f"ë§¤ì¹­ëœ ìƒ˜í”Œ: {len(df_merged)}ê°œ")
            return df_merged
        else:
            # ì •ë‹µ ë°ì´í„° ì—†ì´ ì˜ˆì¸¡ ê²°ê³¼ë§Œ ë¶„ì„
            ic("ì •ë‹µ ë°ì´í„° ì—†ìŒ - ì˜ˆì¸¡ ë¶„í¬ë§Œ ë¶„ì„")
            return df_pred
    
    def analyze_class_predictions(self, df: pd.DataFrame) -> Dict:
        """í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¶„ì„"""
        ic("í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¶„ì„ ì‹œì‘")
        
        analysis = {}
        
        # 1. í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¶„í¬
        pred_distribution = df['predicted_target'].value_counts().sort_index()
        analysis['prediction_distribution'] = {
            str(k): int(v) for k, v in pred_distribution.items()
        }
        # Handle true class distribution if available
        if 'target' in df.columns:
            true_distribution = df['target'].value_counts().sort_index()
            analysis['true_distribution'] = {
            str(k): int(v) for k, v in true_distribution.items()
            }        
        # 2. í´ë˜ìŠ¤ë³„ í‰ê·  ì‹ ë¢°ë„
        confidence_by_class = df.groupby('predicted_target')['confidence'].agg(['mean', 'std', 'count'])
        analysis['confidence_by_predicted_class'] = {
            int(str(k)): {
                'mean_confidence': float(v['mean']),
                'std_confidence': float(v['std']) if not pd.isna(v['std']) else 0.0,
                'count': int(v['count'])
            }
            for k, v in confidence_by_class.iterrows()
        }
        
        # 3. ì •ë‹µì´ ìˆëŠ” ê²½ìš° í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„
        if 'target' in df.columns:
            analysis.update(self._analyze_class_performance_with_ground_truth(df))
        
        return analysis
    
    def _analyze_class_performance_with_ground_truth(self, df: pd.DataFrame) -> Dict:
        """ì •ë‹µ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ì˜ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„"""
        ic("ì •ë‹µ ê¸°ë°˜ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„")
        
        from sklearn.metrics import classification_report, confusion_matrix
        
        analysis = {}
        
        # 1. ì „ì²´ ë¶„ë¥˜ ë³´ê³ ì„œ
        y_true = df['target']
        y_pred = df['predicted_target']
        
        class_names_list = [self.class_names.get(i, f"class_{i}") for i in range(self.num_classes)]
        report = classification_report(y_true, y_pred, 
                                     target_names=class_names_list, 
                                     output_dict=True,
                                     zero_division=0)
        
        # Ensure report is a dictionary
        if not isinstance(report, dict):
            ic("Warning: classification_report did not return a dictionary")
            report = {}
        
        # 2. í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ì¶œ
        class_performance = {}
        for class_id in range(self.num_classes):
            class_name = self.class_names.get(class_id, f"class_{class_id}")
            
            # classification_reportì—ì„œ í•´ë‹¹ í´ë˜ìŠ¤ ë©”íŠ¸ë¦­ ì¶”ì¶œ
            class_metrics = safe_classification_report_access(report, class_name)
            
            # ì¶”ê°€ ë¶„ì„: í•´ë‹¹ í´ë˜ìŠ¤ì˜ ì˜ˆì¸¡ ë¶„í¬
            true_class_samples = df[df['target'] == class_id]
            if len(true_class_samples) > 0:
                # ì •í™•ë„
                correct_predictions = len(true_class_samples[true_class_samples['predicted_target'] == class_id])
                accuracy = correct_predictions / len(true_class_samples)
                
                # í‰ê·  ì‹ ë¢°ë„ (ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ê³¼ í‹€ë¦° ì˜ˆì¸¡ ë¶„ë¦¬)
                correct_samples = true_class_samples[true_class_samples['predicted_target'] == class_id]
                wrong_samples = true_class_samples[true_class_samples['predicted_target'] != class_id]
                
                avg_confidence_correct = correct_samples['confidence'].mean() if len(correct_samples) > 0 else 0
                avg_confidence_wrong = wrong_samples['confidence'].mean() if len(wrong_samples) > 0 else 0
                
                # ê°€ì¥ ìì£¼ í˜¼ë™ë˜ëŠ” í´ë˜ìŠ¤
                most_confused_with = true_class_samples['predicted_target'].value_counts().drop(class_id, errors='ignore')
                most_confused_class = int(most_confused_with.index.values[0]) if len(most_confused_with) > 0 else None
                
                class_performance[class_id] = {
                    'class_name': class_name,
                    'total_samples': len(true_class_samples),
                    'correct_predictions': int(correct_predictions),
                    'accuracy': float(accuracy),
                    'precision': class_metrics.get('precision', 0.0),
                    'recall': class_metrics.get('recall', 0.0),
                    'f1_score': class_metrics.get('f1-score', 0.0),
                    'support': class_metrics.get('support', 0),
                    'avg_confidence_correct': float(avg_confidence_correct),
                    'avg_confidence_wrong': float(avg_confidence_wrong),
                    'confidence_gap': float(avg_confidence_correct - avg_confidence_wrong),
                    'most_confused_with': most_confused_class,
                    'most_confused_with_name': self.class_names.get(most_confused_class, 'None') if most_confused_class is not None else 'None'
                }
        
        analysis['class_performance'] = class_performance
        
        # 3. í˜¼ë™ ë§¤íŠ¸ë¦­ìŠ¤
        cm = confusion_matrix(y_true, y_pred, labels=list(range(self.num_classes)))
        analysis['confusion_matrix'] = cm.tolist()
        
        return analysis
    
    def correlate_with_corruption_data(self, class_analysis: Dict) -> Dict:
        """í´ë˜ìŠ¤ ì„±ëŠ¥ê³¼ corruption ë°ì´í„° ì—°ê´€ì„± ë¶„ì„"""
        ic("Corruption ë°ì´í„°ì™€ ì„±ëŠ¥ ì—°ê´€ì„± ë¶„ì„")
        
        # Corruption ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        corruption_files = {
            'train': self.corruption_dir / 'train_corruption_analysis.csv',
            'test': self.corruption_dir / 'test_corruption_analysis.csv',
            'comparison': self.corruption_dir / 'dataset_comparison.json'
        }
        
        correlations = {}
        
        # Corruption ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ë¶„ì„
        if all(f.exists() for f in corruption_files.values()):
            ic("Corruption ë¶„ì„ ê²°ê³¼ ë°œê²¬, ì—°ê´€ì„± ë¶„ì„ ì§„í–‰")
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° corruption ì •ë³´ ë¡œë“œ
            test_corruption_df = pd.read_csv(corruption_files['test'])
            
            # í´ë˜ìŠ¤ë³„ corruption íŠ¹ì„± ë¶„ì„
            # (ì‹¤ì œë¡œëŠ” íŒŒì¼ëª…ì„ í†µí•´ í´ë˜ìŠ¤ë¥¼ ë§¤í•‘í•´ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì¼ë°˜ì ì¸ corruption íŒ¨í„´ ë¶„ì„)
            
            # 1. íšŒì „ì— ì·¨ì•½í•œ í´ë˜ìŠ¤ ì‹ë³„
            if 'class_performance' in class_analysis:
                rotation_vulnerability = self._identify_rotation_vulnerable_classes(class_analysis['class_performance'])
                correlations['rotation_vulnerability'] = rotation_vulnerability
            
            # 2. ì¡°ëª…ì— ì·¨ì•½í•œ í´ë˜ìŠ¤ ì‹ë³„
            if 'class_performance' in class_analysis:
                lighting_vulnerability = self._identify_lighting_vulnerable_classes(class_analysis['class_performance'])
                correlations['lighting_vulnerability'] = lighting_vulnerability
            
            # 3. ë¸”ëŸ¬ì— ì·¨ì•½í•œ í´ë˜ìŠ¤ ì‹ë³„
            if 'class_performance' in class_analysis:
                blur_vulnerability = self._identify_blur_vulnerable_classes(class_analysis['class_performance'])
                correlations['blur_vulnerability'] = blur_vulnerability
        else:
            ic("Corruption ë¶„ì„ ê²°ê³¼ ì—†ìŒ, ì„±ëŠ¥ ê¸°ë°˜ ì¶”ì •ë§Œ ìˆ˜í–‰")
            correlations = self._estimate_vulnerabilities_from_performance(class_analysis)
        
        return correlations
    
    def _identify_rotation_vulnerable_classes(self, class_performance: Dict) -> Dict:
        """íšŒì „ì— ì·¨ì•½í•œ í´ë˜ìŠ¤ ì‹ë³„"""
        vulnerable_classes = {}
        
        # ì„±ëŠ¥ì´ ë‚®ê³  ì‹ ë¢°ë„ ê²©ì°¨ê°€ í° í´ë˜ìŠ¤ë“¤ì„ íšŒì „ ì·¨ì•½ í´ë˜ìŠ¤ë¡œ ì¶”ì •
        for class_id, perf in class_performance.items():
            vulnerability_score = 0
            
            # ë‚®ì€ ì •í™•ë„ (íšŒì „ìœ¼ë¡œ ì¸í•œ ì„±ëŠ¥ ì €í•˜ ì¶”ì •)
            if perf['accuracy'] < 0.7:
                vulnerability_score += (0.7 - perf['accuracy']) * 10
            
            # ì‹ ë¢°ë„ ê²©ì°¨ (ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ê³¼ í‹€ë¦° ì˜ˆì¸¡ì˜ ì‹ ë¢°ë„ ì°¨ì´)
            confidence_gap = perf.get('confidence_gap', 0)
            if confidence_gap < 0.2:  # ê²©ì°¨ê°€ ì‘ìœ¼ë©´ êµ¬ë¶„ì´ ì–´ë ¤ì›€ì„ ì˜ë¯¸
                vulnerability_score += (0.2 - confidence_gap) * 5
            
            vulnerable_classes[class_id] = {
                'class_name': perf['class_name'],
                'vulnerability_score': float(vulnerability_score),
                'evidence': {
                    'low_accuracy': perf['accuracy'] < 0.7,
                    'low_confidence_gap': confidence_gap < 0.2,
                    'accuracy': perf['accuracy'],
                    'confidence_gap': confidence_gap
                }
            }
        
        # ì·¨ì•½ì„± ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        sorted_vulnerable = sorted(vulnerable_classes.items(), 
                                 key=lambda x: x[1]['vulnerability_score'], reverse=True)
        
        return {
            'ranking': [(int(k), v) for k, v in sorted_vulnerable[:10]],  # ìƒìœ„ 10ê°œ
            'high_risk_classes': [int(k) for k, v in sorted_vulnerable[:5] if v['vulnerability_score'] > 2.0],
            'analysis_method': 'performance_based_estimation'
        }
    
    def _identify_lighting_vulnerable_classes(self, class_performance: Dict) -> Dict:
        """ì¡°ëª…ì— ì·¨ì•½í•œ í´ë˜ìŠ¤ ì‹ë³„"""
        # í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¬¸ì„œëŠ” ì¡°ëª… ë³€í™”ì— ë” ì·¨ì•½í•  ê²ƒìœ¼ë¡œ ì¶”ì •
        # ì—¬ê¸°ì„œëŠ” F1 ì ìˆ˜ê°€ ë‚®ê³  ì •ë°€ë„/ì¬í˜„ìœ¨ ë¶ˆê· í˜•ì´ ìˆëŠ” í´ë˜ìŠ¤ë¥¼ ì¡°ëª… ì·¨ì•½ í´ë˜ìŠ¤ë¡œ ì¶”ì •
        
        vulnerable_classes = {}
        
        for class_id, perf in class_performance.items():
            vulnerability_score = 0
            
            # F1 ì ìˆ˜ê°€ ë‚®ìŒ
            if perf['f1_score'] < 0.8:
                vulnerability_score += (0.8 - perf['f1_score']) * 8
            
            # ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ë¶ˆê· í˜• (ì¡°ëª… ë³€í™”ë¡œ ì¸í•œ feature ë³€í™”)
            precision = perf.get('precision', 0)
            recall = perf.get('recall', 0)
            if precision > 0 and recall > 0:
                imbalance = abs(precision - recall)
                if imbalance > 0.2:
                    vulnerability_score += imbalance * 3
            
            vulnerable_classes[class_id] = {
                'class_name': perf['class_name'],
                'vulnerability_score': float(vulnerability_score),
                'evidence': {
                    'low_f1': perf['f1_score'] < 0.8,
                    'precision_recall_imbalance': abs(precision - recall) > 0.2 if precision > 0 and recall > 0 else False,
                    'f1_score': perf['f1_score'],
                    'precision': precision,
                    'recall': recall
                }
            }
        
        sorted_vulnerable = sorted(vulnerable_classes.items(), 
                                 key=lambda x: x[1]['vulnerability_score'], reverse=True)
        
        return {
            'ranking': [(int(k), v) for k, v in sorted_vulnerable[:10]],
            'high_risk_classes': [int(k) for k, v in sorted_vulnerable[:5] if v['vulnerability_score'] > 1.5],
            'analysis_method': 'f1_precision_recall_based'
        }
    
    def _identify_blur_vulnerable_classes(self, class_performance: Dict) -> Dict:
        """ë¸”ëŸ¬ì— ì·¨ì•½í•œ í´ë˜ìŠ¤ ì‹ë³„"""
        # ì„¸ë¶€ì ì¸ featureì— ì˜ì¡´í•˜ëŠ” í´ë˜ìŠ¤ë“¤ì€ ë¸”ëŸ¬ì— ë” ì·¨ì•½
        # ì—¬ê¸°ì„œëŠ” supportê°€ ë‚®ê³  ì„±ëŠ¥ì´ ë¶ˆì•ˆì •í•œ í´ë˜ìŠ¤ë¥¼ ë¸”ëŸ¬ ì·¨ì•½ í´ë˜ìŠ¤ë¡œ ì¶”ì •
        
        vulnerable_classes = {}
        
        for class_id, perf in class_performance.items():
            vulnerability_score = 0
            
            # ì¬í˜„ìœ¨ì´ íŠ¹íˆ ë‚®ìŒ (ë¸”ëŸ¬ë¡œ ì¸í•œ feature ì†ì‹¤)
            recall = perf.get('recall', 0)
            if recall < 0.7:
                vulnerability_score += (0.7 - recall) * 10
            
            # ì˜ëª»ëœ ì˜ˆì¸¡ì˜ ì‹ ë¢°ë„ê°€ ë†’ìŒ (ë¸”ëŸ¬ë¡œ ì¸í•œ í˜¼ë™)
            avg_confidence_wrong = perf.get('avg_confidence_wrong', 0)
            if avg_confidence_wrong > 0.6:  # í‹€ë ¸ëŠ”ë°ë„ í™•ì‹ 
                vulnerability_score += (avg_confidence_wrong - 0.6) * 5
            
            vulnerable_classes[class_id] = {
                'class_name': perf['class_name'],
                'vulnerability_score': float(vulnerability_score),
                'evidence': {
                    'low_recall': recall < 0.7,
                    'high_wrong_confidence': avg_confidence_wrong > 0.6,
                    'recall': recall,
                    'avg_confidence_wrong': avg_confidence_wrong
                }
            }
        
        sorted_vulnerable = sorted(vulnerable_classes.items(), 
                                 key=lambda x: x[1]['vulnerability_score'], reverse=True)
        
        return {
            'ranking': [(int(k), v) for k, v in sorted_vulnerable[:10]],
            'high_risk_classes': [int(k) for k, v in sorted_vulnerable[:5] if v['vulnerability_score'] > 2.0],
            'analysis_method': 'recall_confidence_based'
        }
    
    def _estimate_vulnerabilities_from_performance(self, class_analysis: Dict) -> Dict:
        """ì„±ëŠ¥ ë°ì´í„°ë§Œìœ¼ë¡œ ì·¨ì•½ì  ì¶”ì •"""
        if 'class_performance' not in class_analysis:
            return {}
        
        return {
            'rotation_vulnerability': self._identify_rotation_vulnerable_classes(class_analysis['class_performance']),
            'lighting_vulnerability': self._identify_lighting_vulnerable_classes(class_analysis['class_performance']),
            'blur_vulnerability': self._identify_blur_vulnerable_classes(class_analysis['class_performance'])
        }
    
    def generate_augmentation_recommendations(self, correlations: Dict) -> Dict:
        """ì·¨ì•½ì  ë¶„ì„ ê¸°ë°˜ ì¦ê°• ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        ic("í´ë˜ìŠ¤ë³„ ì¦ê°• ê¶Œì¥ì‚¬í•­ ìƒì„±")
        
        recommendations = {
            'class_specific_strategies': {},
            'global_strategies': [],
            'progressive_training_plan': {}
        }
        
        # 1. í´ë˜ìŠ¤ë³„ ë§ì¶¤ ì „ëµ
        all_vulnerable_classes = set()
        
        # íšŒì „ ì·¨ì•½ í´ë˜ìŠ¤
        if 'rotation_vulnerability' in correlations:
            rotation_classes = correlations['rotation_vulnerability'].get('high_risk_classes', [])
            for class_id in rotation_classes:
                if class_id not in recommendations['class_specific_strategies']:
                    recommendations['class_specific_strategies'][class_id] = {
                        'class_name': self.class_names.get(class_id, f"class_{class_id}"),
                        'vulnerabilities': [],
                        'augmentation_focus': [],
                        'intensity_multiplier': 1.0
                    }
                
                recommendations['class_specific_strategies'][class_id]['vulnerabilities'].append('rotation')
                recommendations['class_specific_strategies'][class_id]['augmentation_focus'].append({
                    'type': 'rotation',
                    'priority': 'high',
                    'parameters': {
                        'range': 'Â±45Â°',
                        'probability': 0.9,
                        'progressive_steps': ['Â±15Â°', 'Â±30Â°', 'Â±45Â°']
                    }
                })
                recommendations['class_specific_strategies'][class_id]['intensity_multiplier'] *= 1.5
            
            all_vulnerable_classes.update(rotation_classes)
        
        # ì¡°ëª… ì·¨ì•½ í´ë˜ìŠ¤
        if 'lighting_vulnerability' in correlations:
            lighting_classes = correlations['lighting_vulnerability'].get('high_risk_classes', [])
            for class_id in lighting_classes:
                if class_id not in recommendations['class_specific_strategies']:
                    recommendations['class_specific_strategies'][class_id] = {
                        'class_name': self.class_names.get(class_id, f"class_{class_id}"),
                        'vulnerabilities': [],
                        'augmentation_focus': [],
                        'intensity_multiplier': 1.0
                    }
                
                recommendations['class_specific_strategies'][class_id]['vulnerabilities'].append('lighting')
                recommendations['class_specific_strategies'][class_id]['augmentation_focus'].append({
                    'type': 'lighting',
                    'priority': 'high',
                    'parameters': {
                        'brightness_range': '[0.8, 1.8]',
                        'contrast_range': '[0.8, 1.2]',
                        'probability': 0.8
                    }
                })
                recommendations['class_specific_strategies'][class_id]['intensity_multiplier'] *= 1.3
            
            all_vulnerable_classes.update(lighting_classes)
        
        # ë¸”ëŸ¬ ì·¨ì•½ í´ë˜ìŠ¤
        if 'blur_vulnerability' in correlations:
            blur_classes = correlations['blur_vulnerability'].get('high_risk_classes', [])
            for class_id in blur_classes:
                if class_id not in recommendations['class_specific_strategies']:
                    recommendations['class_specific_strategies'][class_id] = {
                        'class_name': self.class_names.get(class_id, f"class_{class_id}"),
                        'vulnerabilities': [],
                        'augmentation_focus': [],
                        'intensity_multiplier': 1.0
                    }
                
                recommendations['class_specific_strategies'][class_id]['vulnerabilities'].append('blur')
                recommendations['class_specific_strategies'][class_id]['augmentation_focus'].append({
                    'type': 'blur',
                    'priority': 'medium',
                    'parameters': {
                        'gaussian_blur_sigma': '[0, 2.0]',
                        'motion_blur_limit': 7,
                        'probability': 0.5
                    }
                })
                recommendations['class_specific_strategies'][class_id]['intensity_multiplier'] *= 1.2
            
            all_vulnerable_classes.update(blur_classes)
        
        # 2. ì „ì—­ ì „ëµ
        if len(all_vulnerable_classes) > self.num_classes * 0.6:  # 60% ì´ìƒì˜ í´ë˜ìŠ¤ê°€ ì·¨ì•½
            recommendations['global_strategies'].append("ëŒ€ë¶€ë¶„ í´ë˜ìŠ¤ê°€ ì·¨ì•½í•˜ë¯€ë¡œ ì „ì—­ì  ê°•í™” ì¦ê°• í•„ìš”")
        
        recommendations['global_strategies'].extend([
            "íšŒì „ ì¦ê°•ì„ ìµœìš°ì„ ìœ¼ë¡œ ì ìš© (Gemini ë¶„ì„ ê¸°ë°˜)",
            "ì¡°ëª… ì¦ê°•ì„ ë‘ ë²ˆì§¸ ìš°ì„ ìˆœìœ„ë¡œ ì ìš©",
            "ì ì§„ì  í›ˆë ¨ìœ¼ë¡œ ì¦ê°• ê°•ë„ ë‹¨ê³„ì  ì¦ê°€"
        ])
        
        # 3. ì ì§„ì  í›ˆë ¨ ê³„íš
        recommendations['progressive_training_plan'] = {
            'phase_1': {
                'duration': '30% of epochs',
                'focus': 'ê¸°ë³¸ feature í•™ìŠµ',
                'augmentation_intensity': 'mild',
                'rotation_range': 'Â±10Â°',
                'lighting_factor': '[0.9, 1.2]'
            },
            'phase_2': {
                'duration': '40% of epochs',
                'focus': 'ì¤‘ê°„ ê°•ë„ robustness',
                'augmentation_intensity': 'medium',
                'rotation_range': 'Â±25Â°',
                'lighting_factor': '[0.8, 1.5]'
            },
            'phase_3': {
                'duration': '30% of epochs',
                'focus': 'ìµœëŒ€ robustness',
                'augmentation_intensity': 'full',
                'rotation_range': 'Â±45Â°',
                'lighting_factor': '[0.8, 1.8]'
            }
        }
        
        return recommendations
    
    def visualize_class_analysis(self, class_analysis: Dict, correlations: Dict) -> Optional[Figure]:
        """í´ë˜ìŠ¤ ë¶„ì„ ê²°ê³¼ ì‹œê°í™”"""
        if 'class_performance' not in class_analysis:
            ic("ì„±ëŠ¥ ë°ì´í„° ì—†ìŒ, ì‹œê°í™” ìƒëµ")
            return None
        
        fig, axes = plt.subplots(2, 3, figsize=(20, 12))
        axes = axes.flatten()
        
        class_performance = class_analysis['class_performance']
        
        # 1. í´ë˜ìŠ¤ë³„ ì •í™•ë„
        class_ids = list(class_performance.keys())
        accuracies = [class_performance[cid]['accuracy'] for cid in class_ids]
        class_names = [class_performance[cid]['class_name'] for cid in class_ids]
        
        axes[0].bar(range(len(class_ids)), accuracies)
        axes[0].set_title('í´ë˜ìŠ¤ë³„ ì •í™•ë„')
        axes[0].set_xlabel('í´ë˜ìŠ¤')
        axes[0].set_ylabel('ì •í™•ë„')
        axes[0].set_xticks(range(len(class_ids)))
        axes[0].set_xticklabels([f"{cid}" for cid in class_ids], rotation=45)
        
        # 2. F1 ì ìˆ˜ ë¶„í¬
        f1_scores = [class_performance[cid]['f1_score'] for cid in class_ids]
        axes[1].bar(range(len(class_ids)), f1_scores, color='orange')
        axes[1].set_title('í´ë˜ìŠ¤ë³„ F1 ì ìˆ˜')
        axes[1].set_xlabel('í´ë˜ìŠ¤')
        axes[1].set_ylabel('F1 ì ìˆ˜')
        axes[1].set_xticks(range(len(class_ids)))
        axes[1].set_xticklabels([f"{cid}" for cid in class_ids], rotation=45)
        
        # 3. ì‹ ë¢°ë„ ê²©ì°¨
        confidence_gaps = [class_performance[cid]['confidence_gap'] for cid in class_ids]
        axes[2].bar(range(len(class_ids)), confidence_gaps, color='green')
        axes[2].set_title('í´ë˜ìŠ¤ë³„ ì‹ ë¢°ë„ ê²©ì°¨ (ì˜¬ë°”ë¥¸ ì˜ˆì¸¡ - í‹€ë¦° ì˜ˆì¸¡)')
        axes[2].set_xlabel('í´ë˜ìŠ¤')
        axes[2].set_ylabel('ì‹ ë¢°ë„ ê²©ì°¨')
        axes[2].set_xticks(range(len(class_ids)))
        axes[2].set_xticklabels([f"{cid}" for cid in class_ids], rotation=45)
        
        # 4. íšŒì „ ì·¨ì•½ì„± ì ìˆ˜
        if 'rotation_vulnerability' in correlations:
            rotation_scores = {}
            for cid, vuln_data in correlations['rotation_vulnerability'].get('ranking', [])[:len(class_ids)]:
                rotation_scores[cid] = vuln_data['vulnerability_score']
            
            rot_scores = [rotation_scores.get(cid, 0) for cid in class_ids]
            axes[3].bar(range(len(class_ids)), rot_scores, color='red')
            axes[3].set_title('íšŒì „ ì·¨ì•½ì„± ì ìˆ˜')
            axes[3].set_xlabel('í´ë˜ìŠ¤')
            axes[3].set_ylabel('ì·¨ì•½ì„± ì ìˆ˜')
            axes[3].set_xticks(range(len(class_ids)))
            axes[3].set_xticklabels([f"{cid}" for cid in class_ids], rotation=45)
        
        # 5. ì¡°ëª… ì·¨ì•½ì„± ì ìˆ˜
        if 'lighting_vulnerability' in correlations:
            lighting_scores = {}
            for cid, vuln_data in correlations['lighting_vulnerability'].get('ranking', [])[:len(class_ids)]:
                lighting_scores[cid] = vuln_data['vulnerability_score']
            
            light_scores = [lighting_scores.get(cid, 0) for cid in class_ids]
            axes[4].bar(range(len(class_ids)), light_scores, color='yellow')
            axes[4].set_title('ì¡°ëª… ì·¨ì•½ì„± ì ìˆ˜')
            axes[4].set_xlabel('í´ë˜ìŠ¤')
            axes[4].set_ylabel('ì·¨ì•½ì„± ì ìˆ˜')
            axes[4].set_xticks(range(len(class_ids)))
            axes[4].set_xticklabels([f"{cid}" for cid in class_ids], rotation=45)
        
        # 6. ìƒ˜í”Œ ìˆ˜ ë¶„í¬
        sample_counts = [class_performance[cid]['total_samples'] for cid in class_ids]
        axes[5].bar(range(len(class_ids)), sample_counts, color='purple')
        axes[5].set_title('í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜')
        axes[5].set_xlabel('í´ë˜ìŠ¤')
        axes[5].set_ylabel('ìƒ˜í”Œ ìˆ˜')
        axes[5].set_xticks(range(len(class_ids)))
        axes[5].set_xticklabels([f"{cid}" for cid in class_ids], rotation=45)
        
        plt.tight_layout()
        return fig
    
    def generate_summary_report(self, class_analysis: Dict, correlations: Dict, 
                              recommendations: Dict) -> str:
        """ì¢…í•© ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        report_path = self.output_dir / 'class_analysis_summary.txt'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¶„ì„ ë° ì¦ê°• ì „ëµ ë³´ê³ ì„œ\n")
            f.write("=" * 60 + "\n\n")
            
            # 1. ì „ì²´ ìš”ì•½
            f.write("## 1. ì „ì²´ ìš”ì•½\n")
            if 'class_performance' in class_analysis:
                class_perf = class_analysis['class_performance']
                avg_accuracy = np.mean([p['accuracy'] for p in class_perf.values()])
                avg_f1 = np.mean([p['f1_score'] for p in class_perf.values()])
                f.write(f"- í‰ê·  í´ë˜ìŠ¤ ì •í™•ë„: {avg_accuracy:.3f}\n")
                f.write(f"- í‰ê·  F1 ì ìˆ˜: {avg_f1:.3f}\n")
                f.write(f"- ë¶„ì„ëœ í´ë˜ìŠ¤ ìˆ˜: {len(class_perf)}\n\n")
            
            # 2. ì·¨ì•½ í´ë˜ìŠ¤ ì‹ë³„
            f.write("## 2. ì·¨ì•½ í´ë˜ìŠ¤ ì‹ë³„\n")
            
            # íšŒì „ ì·¨ì•½ í´ë˜ìŠ¤
            if 'rotation_vulnerability' in correlations:
                rot_classes = correlations['rotation_vulnerability'].get('high_risk_classes', [])
                f.write(f"### íšŒì „ ì·¨ì•½ í´ë˜ìŠ¤ ({len(rot_classes)}ê°œ):\n")
                for cid in rot_classes:
                    class_name = self.class_names.get(cid, f"class_{cid}")
                    f.write(f"- í´ë˜ìŠ¤ {cid} ({class_name})\n")
                f.write("\n")
            
            # ì¡°ëª… ì·¨ì•½ í´ë˜ìŠ¤
            if 'lighting_vulnerability' in correlations:
                light_classes = correlations['lighting_vulnerability'].get('high_risk_classes', [])
                f.write(f"### ì¡°ëª… ì·¨ì•½ í´ë˜ìŠ¤ ({len(light_classes)}ê°œ):\n")
                for cid in light_classes:
                    class_name = self.class_names.get(cid, f"class_{cid}")
                    f.write(f"- í´ë˜ìŠ¤ {cid} ({class_name})\n")
                f.write("\n")
            
            # ë¸”ëŸ¬ ì·¨ì•½ í´ë˜ìŠ¤
            if 'blur_vulnerability' in correlations:
                blur_classes = correlations['blur_vulnerability'].get('high_risk_classes', [])
                f.write(f"### ë¸”ëŸ¬ ì·¨ì•½ í´ë˜ìŠ¤ ({len(blur_classes)}ê°œ):\n")
                for cid in blur_classes:
                    class_name = self.class_names.get(cid, f"class_{cid}")
                    f.write(f"- í´ë˜ìŠ¤ {cid} ({class_name})\n")
                f.write("\n")
            
            # 3. ê¶Œì¥ ì¦ê°• ì „ëµ
            f.write("## 3. ê¶Œì¥ ì¦ê°• ì „ëµ\n")
            
            if 'global_strategies' in recommendations:
                f.write("### ì „ì—­ ì „ëµ:\n")
                for strategy in recommendations['global_strategies']:
                    f.write(f"- {strategy}\n")
                f.write("\n")
            
            if 'progressive_training_plan' in recommendations:
                plan = recommendations['progressive_training_plan']
                f.write("### ì ì§„ì  í›ˆë ¨ ê³„íš:\n")
                for phase, details in plan.items():
                    f.write(f"**{phase.upper()}** ({details['duration']}):\n")
                    f.write(f"  - ëª©í‘œ: {details['focus']}\n")
                    f.write(f"  - íšŒì „ ë²”ìœ„: {details['rotation_range']}\n")
                    f.write(f"  - ì¡°ëª… ë³€í™”: {details['lighting_factor']}\n\n")
            
            # 4. í´ë˜ìŠ¤ë³„ ë§ì¶¤ ì „ëµ
            f.write("## 4. í´ë˜ìŠ¤ë³„ ë§ì¶¤ ì „ëµ\n")
            if 'class_specific_strategies' in recommendations:
                class_strategies = recommendations['class_specific_strategies']
                for cid, strategy in class_strategies.items():
                    f.write(f"### í´ë˜ìŠ¤ {cid} ({strategy['class_name']}):\n")
                    f.write(f"- ì·¨ì•½ì : {', '.join(strategy['vulnerabilities'])}\n")
                    f.write(f"- ì¦ê°• ê°•ë„ ë°°ìˆ˜: {strategy['intensity_multiplier']:.1f}x\n")
                    for aug in strategy['augmentation_focus']:
                        f.write(f"- {aug['type']} ì¦ê°• ({aug['priority']} ìš°ì„ ìˆœìœ„)\n")
                    f.write("\n")
            
            # 5. êµ¬í˜„ ìš°ì„ ìˆœìœ„
            f.write("## 5. êµ¬í˜„ ìš°ì„ ìˆœìœ„\n")
            f.write("1. **íšŒì „ ì¦ê°• êµ¬í˜„** (Critical - 554% ì„±ëŠ¥ ì°¨ì´)\n")
            f.write("   - ì¦‰ì‹œ Â±15Â° íšŒì „ ì ìš©\n")
            f.write("   - ì ì§„ì ìœ¼ë¡œ Â±45Â°ê¹Œì§€ í™•ì¥\n\n")
            f.write("2. **ì¡°ëª… ì¦ê°• êµ¬í˜„** (High - ê³¼ë…¸ì¶œ ë¬¸ì œ)\n")
            f.write("   - ë°ê¸° íŒ©í„° [0.8, 1.8] ì ìš©\n")
            f.write("   - ëŒ€ë¹„ ì¡°ì • í¬í•¨\n\n")
            f.write("3. **ë…¸ì´ì¦ˆ íƒ€ì… ë³€ê²½** (Medium)\n")
            f.write("   - ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ë¹„ì¤‘ ì¦ê°€\n")
            f.write("   - ì„í„ìŠ¤ ë…¸ì´ì¦ˆ ë¹„ì¤‘ ê°ì†Œ\n\n")
            
            # 6. ë‹¤ìŒ ë‹¨ê³„
            f.write("## 6. ë‹¤ìŒ ë‹¨ê³„\n")
            f.write("1. Step C: Conservative Augmentation Test ì§„í–‰\n")
            f.write("2. ê¸°ì¡´ 79% ì„±ëŠ¥ ìœ ì§€í•˜ë©° ì ì§„ì  ê°œì„ \n")
            f.write("3. í´ë˜ìŠ¤ë³„ ë§ì¶¤ ì¦ê°• ë°ì´í„° ìƒì„±\n")
            f.write("4. Progressive training pipeline êµ¬í˜„\n")
        
        return str(report_path)
    
    def run_comprehensive_analysis(self, predictions_csv: str, 
                                 ground_truth_csv: Optional[str] = None):
        """ì¢…í•© í´ë˜ìŠ¤ ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰"""
        ic("ì¢…í•© í´ë˜ìŠ¤ ì„±ëŠ¥ ë¶„ì„ ì‹œì‘")
        
        # 1. ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ
        df = self.load_prediction_results(predictions_csv, ground_truth_csv)
        
        # 2. í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¶„ì„
        class_analysis = self.analyze_class_predictions(df)
        
        # 3. Corruption ë°ì´í„°ì™€ ì—°ê´€ì„± ë¶„ì„
        correlations = self.correlate_with_corruption_data(class_analysis)
        
        # 4. ì¦ê°• ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = self.generate_augmentation_recommendations(correlations)
        
        # 5. ì‹œê°í™”
        fig = self.visualize_class_analysis(class_analysis, correlations)
        if fig:
            viz_path = self.output_dir / 'class_performance_visualization.png'
            fig.savefig(viz_path, dpi=300, bbox_inches='tight')
            plt.close(fig)
        else:
            viz_path = None
        
        # 6. ê²°ê³¼ ì €ì¥
        # í´ë˜ìŠ¤ ë¶„ì„ ê²°ê³¼
        with open(self.output_dir / 'class_analysis.json', 'w', encoding='utf-8') as f:
            # JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ ì²˜ë¦¬
            def convert_numpy(obj):
                if isinstance(obj, np.integer):
                    return int(obj)
                elif isinstance(obj, np.floating):
                    return float(obj)
                elif isinstance(obj, np.ndarray):
                    return obj.tolist()
                return obj
            
            import json
            json.dump(class_analysis, f, indent=2, ensure_ascii=False, default=convert_numpy)
        
        # ì—°ê´€ì„± ë¶„ì„ ê²°ê³¼
        with open(self.output_dir / 'vulnerability_correlations.json', 'w', encoding='utf-8') as f:
            json.dump(correlations, f, indent=2, ensure_ascii=False, default=convert_numpy)
        
        # ê¶Œì¥ì‚¬í•­
        with open(self.output_dir / 'augmentation_recommendations.json', 'w', encoding='utf-8') as f:
            json.dump(recommendations, f, indent=2, ensure_ascii=False, default=convert_numpy)
        
        # 7. ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
        summary_path = self.generate_summary_report(class_analysis, correlations, recommendations)
        
        ic("í´ë˜ìŠ¤ ì„±ëŠ¥ ë¶„ì„ ì™„ë£Œ")
        ic(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {self.output_dir}")
        
        return {
            'class_analysis': str(self.output_dir / 'class_analysis.json'),
            'correlations': str(self.output_dir / 'vulnerability_correlations.json'),
            'recommendations': str(self.output_dir / 'augmentation_recommendations.json'),
            'visualization': str(viz_path) if viz_path else None,
            'summary': summary_path
        }


def main():
    """Fire CLI ì¸í„°í˜ì´ìŠ¤"""
    fire.Fire(ClassPerformanceAnalyzer)


if __name__ == "__main__":
    main()