from pathlib import Path
import torch
import wandb
import numpy as np
from torch.cuda.amp.grad_scaler import GradScaler
from torch.cuda.amp.autocast_mode import autocast
from torch.nn.utils.clip_grad import clip_grad_norm_
import time
import pandas as pd
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from src.utils.metrics import calculate_metrics
from src.utils.utils import EarlyStopping


def get_gpu_memory_info():
    """GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    if torch.cuda.is_available():
        memory_allocated = torch.cuda.memory_allocated() / 1024**3  # GB
        memory_reserved = torch.cuda.memory_reserved() / 1024**3   # GB
        memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB  
        return {
            'allocated': memory_allocated,
            'reserved': memory_reserved, 
            'total': memory_total,
            'free': memory_total - memory_reserved
        }
    return None

class WandBTrainer:
    def __init__(self, model, optimizer, scheduler, loss_fn, train_loader, val_loader, device, config):
        self.model = model
        self.optimizer = optimizer
        self.scheduler = scheduler
        self.loss_fn = loss_fn
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        self.config = config
        self.batch_step = 0

        # ðŸ”§ FIXED: Hydra config í˜¸í™˜ì„± ê°œì„ 
        # WandB í™œì„±í™” ì²´í¬ - í™˜ê²½ ë³€ìˆ˜ì™€ config ëª¨ë‘ í™•ì¸
        wandb_mode = os.environ.get("WANDB_MODE", "online")
        config_wandb_enabled = config.get('wandb', {}).get('enabled', True)  # ðŸ”§ ê¸°ë³¸ê°’ Trueë¡œ ë³€ê²½
        
        # WandB í™œì„±í™” ì¡°ê±´ ê°œì„ 
        self.wandb_enabled = (wandb_mode != "disabled") and config_wandb_enabled
        
        if self.wandb_enabled:
            self._init_wandb()
        else:
            print("ðŸš« WandB logging disabled - Check config.yaml wandb.enabled setting")

        # í›ˆë ¨ ì„¤ì •
        self.use_autocast = config.get('train', {}).get('mixed_precision', False)
        self.scaler = GradScaler() if self.use_autocast else None
        self.history = []
        self.memory_log = []
        self.class_names = self._get_class_names()
        
    def _init_wandb(self):
        """ðŸ”§ ENHANCED: WandB ì´ˆê¸°í™” - Hydra ì‹¤í—˜ ì •ë³´ í¬í•¨"""
        wandb_config = self.config['wandb']
        wandb_username = self.config.get('wandb', {}).get('username', 'default-user')
        
        # âœ… FIXED: Use correct config structure
        experiment_info = self.config.get('experiment', {})
        experiment_name = experiment_info.get('name', 'hydra_experiment')
        experiment_description = experiment_info.get('description', 'Hydra managed experiment')
        experiment_tags = experiment_info.get('tags', [])
        
        # âœ… FIXED: Get augmentation from correct location
        model_name = self.config.get('model', {}).get('name', 'unknown')
        batch_size = self.config.get('train', {}).get('batch_size', 32)
        image_size = self.config.get('data', {}).get('image_size', 224)
        
        # âœ… FIXED: Get augmentation config from top level, not nested in data
        augmentation_config = self.config.get('augmentation', {})
        augmentation_enabled = augmentation_config.get('enabled', False)
        
        # âœ… FIXED: Only use strategy if augmentation is enabled
        if augmentation_enabled:
            augmentation_strategy = augmentation_config.get('strategy', 'basic')
            augmentation_intensity = augmentation_config.get('intensity', 0.7)
        else:
            augmentation_strategy = 'none'
            augmentation_intensity = 0.0
        
        # ì„±ëŠ¥ ì ìˆ˜ í”Œë ˆì´ìŠ¤í™€ë”ê°€ í¬í•¨ëœ ì‹¤í–‰ ì´ë¦„
        run_name = f"{wandb_username}--{experiment_name}-{model_name}-{augmentation_strategy}-b{batch_size}-s{image_size}-(f1_pending)"
        
        # ðŸ”§ Config í‰ë©´í™” - WandBìš© ì„¤ì • ì¤€ë¹„
        flat_config = self._flatten_config(self.config)
        
        # âœ… FIXED: Use actual config values, not defaults
        flat_config.update({
            'augmentation_strategy': augmentation_strategy,
            'augmentation_intensity': augmentation_intensity,
            'augmentation_enabled': augmentation_enabled,
            'experiment_name': experiment_name,  # Add this for tracking
            'experiment_description': experiment_description,
        })
        
        # WandB ëª¨ë“œ í™•ì¸
        wandb_mode = os.environ.get("WANDB_MODE", "online")
        allowed_modes = ['online', 'offline', 'disabled']
        wandb_mode_literal = wandb_mode if wandb_mode in allowed_modes else 'online'
        
        # ðŸ”§ WandB ì´ˆê¸°í™” - í–¥ìƒëœ ë©”íƒ€ë°ì´í„° í¬í•¨
        wandb.init(
            project=wandb_config['project'],
            entity=wandb_config.get('entity'),
            name=run_name,
            tags=list(set(wandb_config.get('tags', []) + experiment_tags)),  # íƒœê·¸ ë³‘í•©
            notes=f"{experiment_description} | Model: {model_name} | Strategy: {augmentation_strategy}",
            config=flat_config,
            mode=wandb_mode_literal,
        )

        # ëª¨ë¸ ê°ì‹œ ì„¤ì •
        if wandb_config.get('watch_model', True):
            wandb.watch(self.model, log='all', log_freq=wandb_config.get('log_frequency', 10))
    
        print(f"ðŸš€ WandB initialized: {run_name}")
        print(f"ðŸ“Š Mode: {wandb_mode}, Project: {wandb_config['project']}")
        print(f"ðŸŽ¯ Experiment: {experiment_name}")
        print(f"ðŸŽ¨ Augmentation: {augmentation_strategy} (intensity: {augmentation_intensity})") 

    def _flatten_config(self, config, parent_key='', sep='_'):
        """ì¤‘ì²©ëœ configë¥¼ WandBìš©ìœ¼ë¡œ í‰ë©´í™”"""
        items = []
        for k, v in config.items():
            new_key = f"{parent_key}{sep}{k}" if parent_key else k
            if isinstance(v, dict):
                items.extend(self._flatten_config(v, new_key, sep=sep).items())
            else:
                items.append((new_key, v))
        return dict(items)
    
    def _get_class_names(self):
        """í´ëž˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°"""
        if hasattr(self.train_loader.dataset, 'classes'):
            return self.train_loader.dataset.classes
        else:
            # ë©”íƒ€ íŒŒì¼ì—ì„œ í´ëž˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° ì‹œë„
            try:
                import pandas as pd
                meta_file = self.config.get('data', {}).get('meta_file', 'data/raw/metadata/meta.csv')
                if os.path.exists(meta_file):
                    meta_df = pd.read_csv(meta_file)
                    return meta_df['class_name'].tolist()
            except:
                pass
            # í´ë°±: ìˆ«ìž í´ëž˜ìŠ¤ëª…
            return [f"class_{i}" for i in range(17)]
    
    def _log_sample_predictions(self, epoch, num_samples=8):
        """ìƒ˜í”Œ ì˜ˆì¸¡ ì´ë¯¸ì§€ë¥¼ WandBì— ë¡œê¹…"""
        if not self.wandb_enabled or not self.config['wandb'].get('log_images', False):
            return
            
        self.model.eval()
        samples_logged = 0
        wandb_images = []
        
        with torch.no_grad():
            for data, target in self.val_loader:
                if samples_logged >= num_samples:
                    break
                    
                data, target = data.to(self.device), target.to(self.device)
                output = self.model(data)
                probabilities = torch.nn.functional.softmax(output, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
                # í…ì„œë¥¼ numpyë¡œ ë³€í™˜í•˜ì—¬ ë¡œê¹…
                for i in range(min(data.size(0), num_samples - samples_logged)):
                    # ì´ë¯¸ì§€ í…ì„œë¥¼ numpyë¡œ ë³€í™˜ (C, H, W) -> (H, W, C)
                    img_np = data[i].cpu().numpy().transpose(1, 2, 0)
                    
                    # ì´ë¯¸ì§€ ì—­ì •ê·œí™”
                    mean = np.array(self.config['data']['mean'])
                    std = np.array(self.config['data']['std'])
                    img_np = img_np * std + mean
                    img_np = np.clip(img_np, 0, 1)
                    
                    true_class = self.class_names[target[i].item()]
                    pred_class = self.class_names[int(predicted[i].item())]
                    conf = confidence[i].item()
                    
                    # ìº¡ì…˜ ìƒì„±
                    caption = f"True: {true_class}\nPred: {pred_class}\nConf: {conf:.3f}"
                    
                    wandb_images.append(wandb.Image(
                        img_np,
                        caption=caption
                    ))
                    
                    samples_logged += 1
                    if samples_logged >= num_samples:
                        break
        
        if wandb_images:
            wandb.log({"val/sample_predictions": wandb_images}, step=self.batch_step)     

    def _log_confusion_matrix(self, y_true, y_pred, epoch):
        """í˜¼ë™ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ WandBì— ë¡œê¹…"""
        if not self.wandb_enabled or not self.config['wandb'].get('log_confusion_matrix', False):
            return
            
        cm = confusion_matrix(y_true, y_pred)
        
        # matplotlib ê·¸ë¦¼ ìƒì„±
        plt.figure(figsize=(12, 10))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=self.class_names,
                yticklabels=self.class_names)
        plt.title(f'Confusion Matrix - Epoch {epoch}')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()

        wandb.log({
            "val/confusion_matrix_plot": wandb.Image(plt),
            "val/confusion_matrix_data": wandb.plot.confusion_matrix(
                probs=None,
                y_true=y_true,
                preds=y_pred,
                class_names=self.class_names
            )
        }, step=self.batch_step)

        plt.close()
    
    def _train_epoch(self, epoch):
        """ðŸ”§ ENHANCED: í›ˆë ¨ ì—í¬í¬ - í–¥ìƒëœ WandB ë¡œê¹…"""
        self.model.train()
        total_loss = 0
        batch_count = 0
        log_freq = self.config['wandb'].get('log_frequency', 10) if self.wandb_enabled else 100
        
        for batch_idx, (data, target) in enumerate(tqdm(self.train_loader, desc=f"Training Epoch {epoch}")):
            data, target = data.to(self.device), target.to(self.device)
            
            self.optimizer.zero_grad()
            
            if self.use_autocast:
                with autocast():
                    output = self.model(data)
                    loss = self.loss_fn(output, target)
                    
                assert isinstance(loss, torch.Tensor), "Loss function must return a torch.Tensor"
                if self.scaler is not None:
                    self.scaler.scale(loss).backward()
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                else:
                    loss.backward()
                    self.optimizer.step()
            else:
                output = self.model(data)
                loss = self.loss_fn(output, target)
                loss.backward()
                
                # ê·¸ëž˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
                clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                self.optimizer.step()
            
            total_loss += loss.item()
            batch_count += 1
            self.batch_step += 1
            
            # ðŸ”§ í†µí•© ë°°ì¹˜ ë¡œê¹…
            if self.wandb_enabled and batch_idx % log_freq == 0:
                batch_log_data = {
                    "batch/step": self.batch_step,
                    "batch/loss": loss.item(),
                    "batch/learning_rate": self.optimizer.param_groups[0]['lr']
                }
                
                # GPU ë©”ëª¨ë¦¬ ì •ë³´ ì¶”ê°€
                mem_info = get_gpu_memory_info()
                if mem_info:
                    batch_log_data["batch/gpu_mem_alloc_gb"] = mem_info['allocated']
                    batch_log_data["batch/gpu_mem_reserved_gb"] = mem_info['reserved']
                    
                # WandBì— ë¡œê¹…
                wandb.log(batch_log_data, step=self.batch_step)

            # ë©”ëª¨ë¦¬ ì •ë¦¬
            del data, target, output, loss
            if batch_count % 20 == 0:
                torch.cuda.empty_cache()
        
        return total_loss / len(self.train_loader)
    
    def _validate_epoch(self, epoch):
        """ê²€ì¦ ì—í¬í¬ - ìƒì„¸ ë©”íŠ¸ë¦­ í¬í•¨"""
        self.model.eval()
        total_loss = 0
        all_preds, all_targets = [], []
        
        with torch.no_grad():
            for data, target in tqdm(self.val_loader, desc=f"Validation Epoch {epoch}"):
                data, target = data.to(self.device), target.to(self.device)
                output = self.model(data)
                
                loss = self.loss_fn(output, target)
                total_loss += loss.item()
                
                preds = torch.argmax(output, dim=1)
                all_preds.extend(preds.cpu().numpy())
                all_targets.extend(target.cpu().numpy())
        
        val_loss = total_loss / len(self.val_loader)
        metrics = calculate_metrics(all_targets, all_preds)
        
        return val_loss, metrics['accuracy'], metrics['f1'], all_targets, all_preds
    
    def train(self):
        """ðŸ”§ ENHANCED: í–¥ìƒëœ í›ˆë ¨ ë£¨í”„ - Hydra + WandB í†µí•©"""
        
        # ê²½ë¡œ ì„¤ì • - Hydra configì—ì„œ ê°€ì ¸ì˜¤ê¸°
        paths_config = self.config.get('paths', {})
        output_dir = Path(paths_config.get('output_dir', 'outputs'))
        log_dir = output_dir / paths_config.get('log_dir', 'logs')
        model_dir = output_dir / paths_config.get('model_dir', 'models')   
         
        # ë””ë ‰í† ë¦¬ ìƒì„±
        log_dir.mkdir(parents=True, exist_ok=True)
        model_dir.mkdir(parents=True, exist_ok=True)        

        # Early Stopping ì„¤ì •
        es_config = self.config['train']['early_stopping']
        best_model_path = model_dir / 'best_model.pth'
    
        early_stopping = EarlyStopping(
            patience=es_config['patience'],
            verbose=True,
            path=best_model_path,
            mode=es_config['mode'],
            metric=es_config['metric']
        )

        start_time = time.time()
        print("ðŸš€ Training has started!")
        
        # ðŸ”§ ëª¨ë¸ ë©”íŠ¸ë¦­ ë¡œê¹…
        if self.wandb_enabled:
            model_metrics = {
                "model/total_parameters": sum(p.numel() for p in self.model.parameters()),
                "model/trainable_parameters": sum(p.numel() for p in self.model.parameters() if p.requires_grad),
                "model/size_mb": sum(p.numel() * p.element_size() for p in self.model.parameters()) / 1024**2
            }
            wandb.log(model_metrics)

        best_f1 = 0
        best_epoch = 0
        epoch = 0

        for epoch in range(1, self.config['train']['epochs'] + 1):
            epoch_start_time = time.time()
            
            # í›ˆë ¨ ë° ê²€ì¦
            train_loss = self._train_epoch(epoch)
            val_loss, val_acc, val_f1, y_true, y_pred = self._validate_epoch(epoch)
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ìŠ¤í…
            if self.scheduler:
                if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
                    self.scheduler.step(val_loss)
                else:
                    self.scheduler.step()
            
            epoch_time = time.time() - epoch_start_time
            
            # ì½˜ì†” ë¡œê¹…
            print(f"Epoch {epoch}/{self.config['train']['epochs']} | "
                  f"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | "
                  f"Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f} | "
                  f"Time: {epoch_time:.1f}s")
                    
            # ì—í¬í¬ ì²´í¬í¬ì¸íŠ¸ ì €ìž¥
            epoch_checkpoint_path = model_dir / f"model_epoch_{epoch}.pth"
            torch.save(self.model.state_dict(), epoch_checkpoint_path)        

            # ìµœì‹  ëª¨ë¸ ìƒíƒœ ì €ìž¥
            last_model_path = model_dir / 'last_model.pth'
            torch.save(self.model.state_dict(), last_model_path)
            
            # ðŸ”§ WandB ì—í¬í¬ ë¡œê¹… - í–¥ìƒëœ ë©”íŠ¸ë¦­
            if self.wandb_enabled:
                epoch_log_data = {
                    "train/epoch": epoch,
                    "train/loss": train_loss,
                    "train/learning_rate": self.optimizer.param_groups[0]['lr'],
                    "val/loss": val_loss,
                    "val/accuracy": val_acc,
                    "val/f1": val_f1,
                    "train/epoch_time": epoch_time
                }

                wandb.log(epoch_log_data, step=self.batch_step)

                # 5 ì—í¬í¬ë§ˆë‹¤ ì¶”ê°€ ì‹œê°í™”
                if epoch % 5 == 0 or epoch == self.config['train']['epochs']:
                    self._log_sample_predictions(epoch)
                    self._log_confusion_matrix(y_true, y_pred, epoch)

            # ìµœê³  ëª¨ë¸ ì¶”ì 
            if val_f1 > best_f1:
                best_f1 = val_f1
                best_epoch = epoch
                
                # WandBì— ìµœê³  ëª¨ë¸ ì €ìž¥
                if self.wandb_enabled and self.config['wandb'].get('log_model', False):
                    model_artifact = wandb.Artifact(
                        name=f"model_epoch_{epoch}",
                        type="model",
                        description=f"Best model at epoch {epoch} with F1: {val_f1:.4f}"
                    )
                    
                    torch.save(self.model.state_dict(), "temp_best_model.pth")
                    model_artifact.add_file("temp_best_model.pth")
                    wandb.log_artifact(model_artifact)
                    os.remove("temp_best_model.pth")
            
            # ížˆìŠ¤í† ë¦¬ ì €ìž¥
            self.history.append({
                'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss,
                'val_acc': val_acc, 'val_f1': val_f1, 'epoch_time': epoch_time
            })
            
            # ë©”ëª¨ë¦¬ ì •ë³´ ë¡œê¹…
            mem_info = get_gpu_memory_info()
            if mem_info:
                self.memory_log.append({
                    'epoch': epoch,
                    'memory_allocated': mem_info['allocated'],
                    'memory_free': mem_info['free']
                })
            
            # Early stopping
            early_stopping(val_f1 if es_config['metric'] == 'val_f1' else val_loss, self.model)
            
            if early_stopping.early_stop:
                print(f"Early stopping triggered at epoch {epoch}")
                break       

        total_time = time.time() - start_time
        print(f"âœ¨ Training finished in {total_time // 60:.0f}m {total_time % 60:.0f}s")
        print(f"ðŸ† Best F1: {best_f1:.4f} at epoch {best_epoch}")
        
        # ìµœì¢… ëª¨ë¸ ì €ìž¥
        last_model_path = model_dir / 'last_model.pth'
        torch.save(self.model.state_dict(), last_model_path)
        print(f"ðŸ’¾ Final model state saved to: {last_model_path}")
        
        # ðŸ”§ WandB ìµœì¢… ìš”ì•½ ë° ì‹¤í–‰ ì´ë¦„ ì—…ë°ì´íŠ¸
        if self.wandb_enabled:
            if wandb.run is not None and getattr(wandb.run, "summary", None) is not None:
                
                # ì‹¤í–‰ ì´ë¦„ì„ F1 ì ìˆ˜ë¡œ ì—…ë°ì´íŠ¸
                original_name = wandb.run.name
                if original_name is not None:
                    new_name = original_name.replace("(f1_pending)", f"f1-{best_f1:.4f}")
                    wandb.run.name = new_name
                
                # ìš”ì•½ ë©”íŠ¸ë¦­ ì„¤ì •
                wandb.run.summary["best_epoch"] = best_epoch
                wandb.run.summary["best_val_f1"] = best_f1
                wandb.run.summary["total_training_time_sec"] = total_time
                wandb.run.summary["total_epochs_run"] = epoch

                if early_stopping.early_stop:
                    wandb.run.summary["early_stopped"] = True
                    wandb.run.summary["early_stop_epoch"] = epoch

                # ìµœê³  ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ
                if self.config['wandb'].get('log_model', False):
                    model_artifact = wandb.Artifact(
                        name=f"best-model-{wandb.run.id}",
                        type="model",
                        description=f"Best model with F1: {best_f1:.4f} at epoch {best_epoch}"
                    )
                    model_artifact.add_file(early_stopping.path)
                    wandb.log_artifact(model_artifact)

                # í›ˆë ¨ ížˆìŠ¤í† ë¦¬ í…Œì´ë¸” ë¡œê¹…
                history_df = pd.DataFrame(self.history)
                wandb.log({"training_history_table": wandb.Table(dataframe=history_df)})

                wandb.finish() 

        # ë¡œì»¬ ë¡œê·¸ ì €ìž¥
        history_df = pd.DataFrame(self.history)
        history_df.to_csv(log_dir / 'training_log.csv', index=False)
        
        if self.memory_log:
            memory_df = pd.DataFrame(self.memory_log)
            memory_df.to_csv(log_dir / 'memory_log.csv', index=False)
            print(f"ðŸ’¾ Memory log saved to {log_dir / 'memory_log.csv'}")
        

    def _log_training_efficiency(self, epoch, epoch_time, train_loss, val_loss):
        """í›ˆë ¨ íš¨ìœ¨ì„± ë©”íŠ¸ë¦­ ë¡œê¹…"""
        
        # íš¨ìœ¨ì„± ë©”íŠ¸ë¦­ ê³„ì‚°
        samples_per_second = len(self.train_loader.dataset) / epoch_time
        loss_improvement = self.history[-2]['train_loss'] - train_loss if len(self.history) > 1 else 0
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
        if torch.cuda.is_available():
            memory_efficiency = torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated()
            wandb.log({
                "training_samples_per_second": samples_per_second,
                "loss_improvement_rate": loss_improvement,
                "memory_efficiency": memory_efficiency,
                "gpu_utilization": torch.cuda.utilization() if hasattr(torch.cuda, 'utilization') else 0
            })