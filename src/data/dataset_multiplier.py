# src/data/dataset_multiplier.py
"""
Dataset Multiplication Engine
ëŒ€ìš©ëŸ‰ ì¦ê°• ë°ì´í„°ì…‹ ìƒì„±ê¸° - ì²´ê³„ì ì´ê³  íš¨ìœ¨ì ì¸ ë°ì´í„° í™•ì¥
"""

import os
import cv2
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import albumentations as A
from albumentations.pytorch import ToTensorV2
import json
from tqdm import tqdm
from icecream import ic
import fire
from collections import defaultdict
import shutil
from datetime import datetime


class DatasetMultiplier:
    """ì²´ê³„ì ì¸ ë°ì´í„°ì…‹ ì¦ê°• ë° ì €ì¥ ì‹œìŠ¤í…œ"""
    
    def __init__(self, 
                 source_dir: str = "data/raw",
                 output_base_dir: str = "data/augmented_datasets",
                 csv_file: str = "data/raw/metadata/train.csv",
                 meta_file: str = "data/raw/metadata/meta.csv"):
        """
        ì´ˆê¸°í™”
        Args:
            source_dir: ì›ë³¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
            output_base_dir: ì¦ê°• ë°ì´í„°ì…‹ ì €ì¥ ê¸°ë³¸ ë””ë ‰í† ë¦¬
            csv_file: ì›ë³¸ CSV íŒŒì¼
            meta_file: ë©”íƒ€ë°ì´í„° íŒŒì¼
        """
        self.source_dir = Path(source_dir)
        self.output_base_dir = Path(output_base_dir)
        self.csv_file = csv_file
        self.meta_file = meta_file
        
        # ë°ì´í„° ë¡œë“œ
        self.df = pd.read_csv(csv_file)
        self.meta_df = pd.read_csv(meta_file)
        
        # í´ë˜ìŠ¤ ì •ë³´
        self.class_info = dict(zip(self.meta_df['target'], self.meta_df['class_name']))
        self.class_distribution = self.df['target'].value_counts().sort_index()
        
        ic("ğŸ“Š Dataset Multiplier ì´ˆê¸°í™” ì™„ë£Œ")
        ic(f"ì›ë³¸ ìƒ˜í”Œ ìˆ˜: {len(self.df)}")
        ic(f"í´ë˜ìŠ¤ ìˆ˜: {len(self.class_info)}")
        ic(f"í´ë˜ìŠ¤ë³„ ë¶„í¬: {dict(self.class_distribution.head())}")
        
    def create_augmentation_strategy(self, strategy_name: str, intensity: float = 0.7) -> A.Compose:
        """ì¦ê°• ì „ëµ ìƒì„±"""
        
        if strategy_name == "volume_focused":
            # V1: ëŒ€ìš©ëŸ‰ ìƒì„± - ë‹¤ì–‘í•œ ë³€í˜•
            return A.Compose([
            A.OneOf([
                A.Rotate(
                limit=15, 
                border_mode=cv2.BORDER_CONSTANT, 
                p=1.0
                ),
                A.Rotate(
                limit=30, 
                border_mode=cv2.BORDER_CONSTANT, 
                p=1.0
                ),
                A.Rotate(
                limit=45, 
                border_mode=cv2.BORDER_CONSTANT, 
                p=1.0
                ),
            ], p=0.8),
            
            A.OneOf([
                A.RandomBrightnessContrast(
                brightness_limit=0.2, 
                contrast_limit=0.2, 
                p=1.0
                ),
                A.RandomBrightnessContrast(
                brightness_limit=0.3, 
                contrast_limit=0.3, 
                p=1.0
                ),
                A.RandomGamma(
                gamma_limit=(80, 120), 
                p=1.0
                ),
            ], p=0.7),
            
            A.OneOf([
                A.GaussianBlur(
                blur_limit=3, 
                p=1.0
                ),
                A.MotionBlur(
                blur_limit=5, 
                p=1.0
                ),
                A.GaussNoise(
                    std_range=(0.02, 0.1),  # Changed from var_limit to std_range, normalized to [0,1]
                    p=0.6
                ),
            ], p=0.5),
            
            A.Perspective(
                scale=(0.05, 0.1), 
                keep_size=True, 
                p=0.4
            ),
            A.ImageCompression(
                quality_range=(70, 95),  # Changed from quality_lower/quality_upper to quality_range
                p=0.3
            ),
            ])
            
        elif strategy_name == "test_focused":
            # V2: í…ŒìŠ¤íŠ¸ ì¡°ê±´ ì‹œë®¬ë ˆì´ì…˜
            return A.Compose([
            # íšŒì „ ì¤‘ì‹¬ (554% ì°¨ì´ í•´ê²°)
            A.Rotate(
            limit=25, 
            border_mode=cv2.BORDER_CONSTANT, 
            p=0.9
            ),
            
            # ê³¼ë…¸ì¶œ ì‹œë®¬ë ˆì´ì…˜ (46% vs 20% ì°¨ì´)
            A.OneOf([
            A.RandomBrightnessContrast(
                brightness_limit=0.4,
                contrast_limit=0.2,
                p=1.0
            ),
            # Moderate range
            A.RandomGamma(
                gamma_limit=(1.0, 1.5),
                p=1.0
            ),
            ], p=0.8),
            
            # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ (í…ŒìŠ¤íŠ¸ì…‹ íŠ¹ì„±)
            A.GaussNoise(
            std_range=(0.02, 0.1),  # Changed from var_limit to std_range, normalized to [0,1]
            p=0.6
            ),
            
            # ì›ê·¼ ì™œê³¡
            A.Perspective(
            scale=(0.05, 0.15), 
            keep_size=True, 
            p=0.5
            ),
            ])
        elif strategy_name == "balanced":
            # V3: í´ë˜ìŠ¤ ê· í˜• - ë³´ìˆ˜ì  ì¦ê°•
            return A.Compose([
            A.Rotate(
                limit=20, 
                border_mode=cv2.BORDER_CONSTANT, 
                p=0.7
            ),
            A.RandomBrightnessContrast(
                brightness_limit=0.25, 
                contrast_limit=0.25, 
                p=0.6
            ),
            A.OneOf([
                A.GaussianBlur(
                blur_limit=(3,7), 
                p=1.0
                ),
                A.GaussNoise(
                std_range=(0.01, 0.05),  # Changed from var_limit to std_range, normalized to [0,1]
                p=1.0
                ),
            ], p=0.4),
            A.Perspective(
                scale=(0.02, 0.08), 
                keep_size=True, 
                p=0.3
            ),
            ])
        else:
            raise ValueError(f"Unknown strategy: {strategy_name}")
    
    def calculate_multiplication_targets(self, strategy: str, target_multiplier: int) -> Dict[int, int]:
        """í´ë˜ìŠ¤ë³„ ì¦ê°• ëª©í‘œ ê³„ì‚°"""
        targets = {}
        
        if strategy == "balanced":
            # ëª¨ë“  í´ë˜ìŠ¤ë¥¼ ìµœëŒ€ í´ë˜ìŠ¤ í¬ê¸°ë¡œ ë§ì¶¤
            max_class_size = self.class_distribution.max()
            target_size = max_class_size * target_multiplier
            
            for class_id, current_size in self.class_distribution.items():
                targets[class_id] = target_size
                
        else:
            # ê· ë“± ì¦ê°•
            for class_id, current_size in self.class_distribution.items():
                targets[class_id] = current_size * target_multiplier
        
        return targets
    
    def generate_augmented_samples(self, 
                                 image_path: str, 
                                 transform: A.Compose, 
                                 num_augmentations: int,
                                 base_filename: str) -> List[Tuple[np.ndarray, str]]:
        """ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ì—¬ëŸ¬ ì¦ê°• ìƒ˜í”Œ ìƒì„±"""
        
        # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)
        if image is None:
            ic(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
            return []
        
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        augmented_samples = []
        
        # ì›ë³¸ í¬í•¨
        augmented_samples.append((image, f"{base_filename}_original.jpg"))
        
        # ì¦ê°• ìƒ˜í”Œ ìƒì„±
        for i in range(num_augmentations - 1):  # -1 because we include original
            try:
                augmented = transform(image=image)
                aug_image = augmented['image']
                aug_filename = f"{base_filename}_aug_{i:03d}.jpg"
                augmented_samples.append((aug_image, aug_filename))
            except Exception as e:
                ic(f"âš ï¸ ì¦ê°• ì‹¤íŒ¨: {base_filename}, aug {i}: {e}")
                continue
        
        return augmented_samples
    
    def save_augmented_dataset(self, 
                             dataset_name: str,
                             strategy: str,
                             target_multiplier: int,
                             batch_size: int = 100) -> str:
        """ì¦ê°• ë°ì´í„°ì…‹ ìƒì„± ë° ì €ì¥"""
        
        ic(f"ğŸš€ {dataset_name} ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘")
        ic(f"ì „ëµ: {strategy}, ë°°ìˆ˜: {target_multiplier}x")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        output_dir = self.output_base_dir / dataset_name
        images_dir = output_dir / "train"
        metadata_dir = output_dir / "metadata"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        images_dir.mkdir(parents=True, exist_ok=True)
        metadata_dir.mkdir(parents=True, exist_ok=True)
        
        # ì¦ê°• ì „ëµ ë° ëª©í‘œ ì„¤ì •
        transform = self.create_augmentation_strategy(strategy)
        multiplication_targets = self.calculate_multiplication_targets(strategy, target_multiplier)
        
        # ìƒˆ CSV ë°ì´í„° ì¤€ë¹„
        new_csv_data = []
        generation_stats = defaultdict(int)
        
        # í´ë˜ìŠ¤ë³„ ì²˜ë¦¬
        total_classes = len(self.class_distribution)
        
        for class_idx, (class_id, current_count) in enumerate(self.class_distribution.items()):
            target_count = multiplication_targets[class_id]
            augmentations_per_image = target_count // current_count
            
            ic(f"í´ë˜ìŠ¤ {class_id} ({self.class_info[class_id]}): "
               f"{current_count} â†’ {target_count} ({augmentations_per_image}x)")
            
            # í•´ë‹¹ í´ë˜ìŠ¤ ì´ë¯¸ì§€ë“¤ ê°€ì ¸ì˜¤ê¸°
            class_images = self.df[self.df['target'] == class_id]
            
            # ë°°ì¹˜ ì²˜ë¦¬
            batch_count = 0
            batch_images = []
            
            with tqdm(total=len(class_images), 
                     desc=f"í´ë˜ìŠ¤ {class_id} ì²˜ë¦¬ì¤‘",
                     leave=False) as pbar:
                
                for _, row in class_images.iterrows():
                    source_image_path = self.source_dir / "train" / row['ID']
                    base_filename = Path(row['ID']).stem
                    
                    # ì¦ê°• ìƒ˜í”Œ ìƒì„±
                    augmented_samples = self.generate_augmented_samples(
                        str(source_image_path),
                        transform,
                        augmentations_per_image,
                        f"class_{class_id}_{base_filename}"
                    )
                    
                    # ë°°ì¹˜ì— ì¶”ê°€
                    for aug_image, aug_filename in augmented_samples:
                        batch_images.append((aug_image, aug_filename, class_id))
                        
                        # CSV ë°ì´í„° ì¶”ê°€
                        new_csv_data.append({
                            'ID': aug_filename,
                            'target': class_id
                        })
                    
                    # ë°°ì¹˜ ì €ì¥
                    if len(batch_images) >= batch_size:
                        self._save_batch(batch_images, images_dir)
                        generation_stats[class_id] += len(batch_images)
                        batch_images = []
                        batch_count += 1
                    
                    pbar.update(1)
                
                # ë‚¨ì€ ë°°ì¹˜ ì €ì¥
                if batch_images:
                    self._save_batch(batch_images, images_dir)
                    generation_stats[class_id] += len(batch_images)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        self._save_metadata(new_csv_data, metadata_dir, dataset_name, generation_stats)
        
        # ìƒì„± ìš”ì•½
        total_generated = sum(generation_stats.values())
        ic(f"âœ… {dataset_name} ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
        ic(f"ì´ ìƒì„± ìƒ˜í”Œ: {total_generated:,}")
        ic(f"ì €ì¥ ìœ„ì¹˜: {output_dir}")
        
        return str(output_dir)
    
    def _save_batch(self, batch_images: List[Tuple[np.ndarray, str, int]], output_dir: Path):
        """ì´ë¯¸ì§€ ë°°ì¹˜ ì €ì¥"""
        for image, filename, class_id in batch_images:
            output_path = output_dir / filename
            
            # RGB to BGR for cv2
            image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
            cv2.imwrite(str(output_path), image_bgr)
    
    def _save_metadata(self, csv_data: List[Dict], metadata_dir: Path, 
                      dataset_name: str, stats: Dict[int, int]):
        """ë©”íƒ€ë°ì´í„° íŒŒì¼ë“¤ ì €ì¥"""
        
        # ìƒˆ train.csv ì €ì¥
        new_df = pd.DataFrame(csv_data)
        train_csv_path = metadata_dir / "train.csv"
        new_df.to_csv(train_csv_path, index=False)
        
        # ì›ë³¸ meta.csv ë³µì‚¬
        meta_csv_path = metadata_dir / "meta.csv"
        shutil.copy2(self.meta_file, meta_csv_path)
        
        # ìƒì„± í†µê³„ ì €ì¥
        stats_path = metadata_dir / "generation_stats.json"
        generation_info = {
            'dataset_name': dataset_name,
            'generation_timestamp': datetime.now().isoformat(),
            'total_samples': sum(stats.values()),
            'original_samples': len(self.df),
            'multiplication_factor': sum(stats.values()) / len(self.df),
            'class_statistics': {
                str(class_id): {
                    'generated_count': count,
                    'class_name': self.class_info[class_id]
                } for class_id, count in stats.items()
            }
        }
        
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(generation_info, f, indent=2, ensure_ascii=False)
        
        ic(f"ğŸ“‹ ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_dir}")
    
    def generate_all_variants(self):
        """ëª¨ë“  ë°ì´í„°ì…‹ ë³€í˜• ìƒì„±"""
        
        variants = [
            ("v1_volume_20x", "volume_focused", 20),
            ("v2_test_focused_10x", "test_focused", 10),
            ("v3_balanced_15x", "balanced", 15)
        ]
        
        results = {}
        
        for dataset_name, strategy, multiplier in variants:
            ic(f"\nğŸ¯ {dataset_name} ìƒì„± ì‹œì‘")
            try:
                output_path = self.save_augmented_dataset(dataset_name, strategy, multiplier)
                results[dataset_name] = {
                    'status': 'success',
                    'path': output_path,
                    'strategy': strategy,
                    'multiplier': multiplier
                }
                ic(f"âœ… {dataset_name} ì™„ë£Œ")
            except Exception as e:
                ic(f"âŒ {dataset_name} ì‹¤íŒ¨: {e}")
                results[dataset_name] = {
                    'status': 'failed',
                    'error': str(e)
                }
        
        # ì „ì²´ ìš”ì•½ ì €ì¥
        summary_path = self.output_base_dir / "generation_summary.json"
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        ic(f"ğŸ‰ ëª¨ë“  ë³€í˜• ìƒì„± ì™„ë£Œ. ìš”ì•½: {summary_path}")
        return results


def main():
    """Fire CLI ì¸í„°í˜ì´ìŠ¤"""
    fire.Fire(DatasetMultiplier)


if __name__ == "__main__":
    main()