# src/data/pure_volume_generator.py
"""
Pure Volume Dataset Generator - No Rotation Hypothesis Test
ìˆœìˆ˜ ë³¼ë¥¨ ì¦ê°• (íšŒì „ ì—†ìŒ) - ê°€ì„¤ ê²€ì¦ìš© ë°ì´í„°ì…‹ ìƒì„±ê¸°
"""

import os
import cv2
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import albumentations as A
from albumentations.pytorch import ToTensorV2
import json
from tqdm import tqdm
from icecream import ic
import fire
from collections import defaultdict
import shutil
from datetime import datetime


class PureVolumeGenerator:
    """íšŒì „ ì—†ëŠ” ìˆœìˆ˜ ë³¼ë¥¨ ì¦ê°• ë°ì´í„°ì…‹ ìƒì„±ê¸°"""
    
    def __init__(self, 
                 source_dir: str = "data/raw",
                 output_base_dir: str = "data/augmented_datasets",
                 csv_file: str = "data/raw/metadata/train.csv",
                 meta_file: str = "data/raw/metadata/meta.csv"):
        
        self.source_dir = Path(source_dir)
        self.output_base_dir = Path(output_base_dir)
        self.csv_file = csv_file
        self.meta_file = meta_file
        
        # ë°ì´í„° ë¡œë“œ
        self.df = pd.read_csv(csv_file)
        self.meta_df = pd.read_csv(meta_file)
        
        # í´ë˜ìŠ¤ ì •ë³´
        self.class_info = dict(zip(self.meta_df['target'], self.meta_df['class_name']))
        self.class_distribution = self.df['target'].value_counts().sort_index()
        
        ic("ğŸš€ Pure Volume Generator ì´ˆê¸°í™”")
        ic(f"ì›ë³¸ ìƒ˜í”Œ ìˆ˜: {len(self.df)}")
        ic(f"í´ë˜ìŠ¤ ìˆ˜: {len(self.class_info)}")
        # ic(f"í´ë˜ìŠ¤ ë¶„í¬:\n{self.class_distribution.to_dict()}")
        ic(self.df.columns)

    def get_pure_volume_augmentation(self) -> A.Compose:
        """
        ìˆœìˆ˜ ë³¼ë¥¨ ì¦ê°• íŒŒì´í”„ë¼ì¸ (íšŒì „ ì—†ìŒ)
        
        Focus Areas (from corruption analysis):
        - Brightness/Contrast: Test data 11.2% brighter
        - Noise: Switch from impulse to gaussian (test data dominant)
        - Quality: Blur, compression variations
        - NO ROTATION: Avoid artificial rotation artifacts
        """
        
        return A.Compose([
            # ğŸ”† ì¡°ëª… ê°œì„  (Test data 11.2% brighter than train)
            A.OneOf([
                # A.RandomBrightnessContrast(
                #     brightness_limit=0.15,  # ë°ê¸° ì¡°ì • (í…ŒìŠ¤íŠ¸ ë°ì´í„° ë§¤ì¹­)
                #     contrast_limit=0.15,
                #     p=0.8
                # ),
                A.RandomGamma(
                    gamma_limit=(85, 115),  # ê°ë§ˆ ë³´ì •
                    p=0.6
                ),
                A.CLAHE(
                    clip_limit=2.0,  # ëŒ€ë¹„ ì œí•œ ì ì‘í˜• íˆìŠ¤í† ê·¸ë¨ ê· ë“±í™”
                    tile_grid_size=(8, 8),
                    p=0.4
                )
            ], p=0.7),
            
            # ğŸ”Š ë…¸ì´ì¦ˆ íƒ€ì… ì „í™˜ (Impulse â†’ Gaussian)
            # A.OneOf([
            #     A.GaussNoise(
            #         mean_range=(10.0, 50.0),  # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ë§¤ì¹­
            #         mean=0,
            #         p=0.8
            #     ),
            #     A.ISONoise(
            #         color_shift=(0.01, 0.05),  # ISO ë…¸ì´ì¦ˆ ì‹œë®¬ë ˆì´ì…˜
            #         intensity=(0.1, 0.5),
            #         p=0.6
            #     ),
            #     A.MultiplicativeNoise(
            #         multiplier=[0.9, 1.1],
            #         per_channel=True,
            #         p=0.4
            #     )
            # ], p=0.6),
            
            # ğŸ“· í’ˆì§ˆ ë³€í™” (ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤ìº”/ì´¬ì˜ ì¡°ê±´)
            # A.OneOf([
            #     A.MotionBlur(
            #         blur_limit=3,  # ê²½ë¯¸í•œ ëª¨ì…˜ ë¸”ëŸ¬
            #         p=0.5
            #     ),
            #     A.GaussianBlur(
            #         blur_limit=3,  # ê²½ë¯¸í•œ ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
            #         p=0.5
            #     ),
            #     A.MedianBlur(
            #         blur_limit=3,  # ë…¸ì´ì¦ˆ ì œê±° íš¨ê³¼
            #         p=0.3
            #     )
            # ], p=0.5),
            
            # ğŸ“„ ì••ì¶•/í’ˆì§ˆ ì•„í‹°íŒ©íŠ¸
            # A.OneOf([
            #     A.ImageCompression(
            #         quality_range=(85,100),  # ë†’ì€ í’ˆì§ˆ ìœ ì§€
            #         p=0.7
            #     ),
            #     A.Downscale(
            #        scale_range=(0.9,0.99),  # ê²½ë¯¸í•œ í•´ìƒë„ ê°ì†Œ
            #         interpolation_pair=cv2.INTER_LINEAR,
            #         p=0.5
            #     )
            # ], p=0.4),
            
            # ğŸ¨ ìƒ‰ìƒ ë¯¸ì„¸ ì¡°ì • (ë¬¸ì„œ ìŠ¤ìº” ì¡°ê±´ ì‹œë®¬ë ˆì´ì…˜)
            # A.OneOf([
            #     A.HueSaturationValue(
            #         hue_shift_limit=5,      # ë¯¸ì„¸í•œ ìƒ‰ì¡° ë³€í™”
            #         sat_shift_limit=10,     # ì±„ë„ ì¡°ì •
            #         val_shift_limit=5,      # ëª…ë„ ì¡°ì •
            #         p=0.6
            #     ),
                # A.RGBShift(
                #     r_shift_limit=10,
                #     g_shift_limit=10,
                #     b_shift_limit=10,
                #     p=0.5
                # ),
            #     A.ChannelShuffle(p=0.1)  # ê·¹íˆ ë“œë¬¼ê²Œ ì±„ë„ ì„ê¸°
            # ], p=0.3),
            
            # ğŸ”„ ìµœì¢… ì „ì²˜ë¦¬
            A.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225],
                max_pixel_value=255.0,
                p=1.0
            )
        ])

    def generate_pure_volume_dataset(self, 
                                   multiplier: int = 3,
                                   output_name: str = "pure_volume_3X_no_rotation") -> Path:
        """
        ìˆœìˆ˜ ë³¼ë¥¨ ë°ì´í„°ì…‹ ìƒì„± (íšŒì „ ì—†ìŒ)
        
        Args:
            multiplier: ë°ì´í„° ì¦ê°• ë°°ìˆ˜ (ê¸°ë³¸ 20ë°°)
            output_name: ì¶œë ¥ ë””ë ‰í† ë¦¬ ì´ë¦„
        
        Returns:
            ìƒì„±ëœ ë°ì´í„°ì…‹ ê²½ë¡œ
        """
        
        ic(f"ğŸ¯ ìˆœìˆ˜ ë³¼ë¥¨ ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘ (ë°°ìˆ˜: {multiplier})")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        output_dir = self.output_base_dir / output_name
        train_dir = output_dir / "train"
        val_dir = output_dir / "val"
        metadata_dir = output_dir / "metadata"
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        for dir_path in [train_dir, val_dir, metadata_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
            ic(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±: {dir_path}")
        
        # í´ë˜ìŠ¤ë³„ ì„œë¸Œë””ë ‰í† ë¦¬ ìƒì„±
        # for class_id in self.class_info.keys():
        #     (train_dir / str(class_id)).mkdir(exist_ok=True)
        #     (val_dir / str(class_id)).mkdir(exist_ok=True)
        
        # ì¦ê°• íŒŒì´í”„ë¼ì¸ ì„¤ì •
        augmentation = self.get_pure_volume_augmentation()
        
        # ì§„í–‰ ìƒí™© ì¶”ì 
        train_records = []
        val_records = []
        generation_stats = {
            'total_generated': 0,
            'train_generated': 0,
            'val_generated': 0,
            'class_distribution': defaultdict(int),
            'generation_time': datetime.now().isoformat(),
            'strategy': 'pure_volume_no_rotation',
            'multiplier': multiplier,
            'augmentation_details': {
                'rotation': False,
                'brightness_contrast': True,
                'noise_gaussian': True,
                'quality_variations': True,
                'color_adjustments': True
            }
        }
        
        # í´ë˜ìŠ¤ë³„ ë°ì´í„° ìƒì„±
        for class_id in tqdm(self.class_info.keys(), desc="í´ë˜ìŠ¤ë³„ ì²˜ë¦¬"):
            class_samples = self.df[self.df['target'] == class_id]
            original_count = len(class_samples)
            target_count = original_count * multiplier
            
            ic(f"ğŸ² í´ë˜ìŠ¤ {class_id} ({self.class_info[class_id]}): {original_count} â†’ {target_count}")
            
            generated_count = 0
            
            # ê° ì›ë³¸ ì´ë¯¸ì§€ì— ëŒ€í•´ ì¦ê°• ìƒì„±
            for _, row in tqdm(class_samples.iterrows(), 
                             desc=f"í´ë˜ìŠ¤ {class_id} ì¦ê°•", 
                             total=len(class_samples),
                             leave=False):
                
                # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
                # img_path = self.source_dir / "train" / str(class_id) / row['ID']
                img_path = self.source_dir / "train" / row['ID']
                
                if not img_path.exists():
                    ic(f"âš ï¸ ì´ë¯¸ì§€ ì—†ìŒ: {img_path}")
                    continue
                
                image = cv2.imread(str(img_path))
                if image is None:
                    ic(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
                    continue
                
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                
                # ê° ì›ë³¸ì— ëŒ€í•´ multiplierë§Œí¼ ì¦ê°• ìƒì„±
                for aug_idx in range(multiplier):
                    try:
                        # ì¦ê°• ì ìš©
                        augmented = augmentation(image=image)
                        aug_image = augmented['image']
                        
                        # í…ì„œë¥¼ ë‹¤ì‹œ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                        if hasattr(aug_image, 'numpy'):
                            aug_image = aug_image.numpy()
                        
                        # ì •ê·œí™” í•´ì œ ë° ì´ë¯¸ì§€ í˜•ì‹ ë³µì›
                        if aug_image.dtype != np.uint8:
                            # ì •ê·œí™” í•´ì œ
                            mean = np.array([0.485, 0.456, 0.406])
                            std = np.array([0.229, 0.224, 0.225])
                            
                            if len(aug_image.shape) == 3 and aug_image.shape[0] == 3:
                                # CHW â†’ HWC ë³€í™˜
                                aug_image = np.transpose(aug_image, (1, 2, 0))
                            
                            # ì •ê·œí™” í•´ì œ
                            aug_image = aug_image * std + mean
                            aug_image = np.clip(aug_image * 255, 0, 255).astype(np.uint8)
                        
                        # ì €ì¥ ê²½ë¡œ ê²°ì • (80/20 ë¶„í• )
                        is_validation = (generated_count % 5 == 4)  # 20% ê²€ì¦ìš©
                        base_dir = val_dir if is_validation else train_dir
                        
                        # íŒŒì¼ëª… ìƒì„±
                        base_name = Path(row['ID']).stem
                        new_filename = f"{base_name}_aug_{aug_idx:03d}.jpg"
                        save_path = base_dir / new_filename
                        
                        # ì´ë¯¸ì§€ ì €ì¥
                        aug_image_bgr = cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR)
                        cv2.imwrite(str(save_path), aug_image_bgr, 
                                  [cv2.IMWRITE_JPEG_QUALITY, 95])
                        
                        # ë©”íƒ€ë°ì´í„° ê¸°ë¡
                        record = {
                        'ID': new_filename,      # 'image_name' í‚¤ë¥¼ 'ID'ë¡œ ë³€ê²½
                        'target': class_id  
                        }
                        if is_validation:
                            val_records.append(record)
                            generation_stats['val_generated'] += 1
                        else:
                            train_records.append(record)
                            generation_stats['train_generated'] += 1
                        
                        generated_count += 1
                        generation_stats['total_generated'] += 1
                        generation_stats['class_distribution'][class_id] += 1
                        
                    except Exception as e:
                        ic(f"âš ï¸ ì¦ê°• ì‹¤íŒ¨: {row['ID']}, ì˜¤ë¥˜: {e}")
                        continue
        
        # ë©”íƒ€ë°ì´í„° CSV íŒŒì¼ ì €ì¥
        train_df = pd.DataFrame(train_records)
        val_df = pd.DataFrame(val_records)
        
        train_csv_path = metadata_dir / "train.csv"
        val_csv_path = metadata_dir / "val.csv"
        
        train_df.to_csv(train_csv_path, index=False)
        val_df.to_csv(val_csv_path, index=False)
        
        # ë©”íƒ€ë°ì´í„° ë³µì‚¬
        meta_csv_path = metadata_dir / "meta.csv"
        shutil.copy2(self.meta_file, meta_csv_path)
        
        # ìƒì„± í†µê³„ ì €ì¥
        stats_path = output_dir / "generation_stats.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(generation_stats, f, indent=2, ensure_ascii=False)
        
        # ê²°ê³¼ ìš”ì•½
        ic("âœ… ìˆœìˆ˜ ë³¼ë¥¨ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
        ic(f"ğŸ“Š ì´ ìƒì„±: {generation_stats['total_generated']}")
        ic(f"ğŸ¯ í›ˆë ¨ìš©: {generation_stats['train_generated']}")
        ic(f"ğŸ” ê²€ì¦ìš©: {generation_stats['val_generated']}")
        ic(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {output_dir}")
        
        return output_dir

    def create_training_config(self, dataset_path: Path) -> Path:
        """ìˆœìˆ˜ ë³¼ë¥¨ ë°ì´í„°ì…‹ìš© í›ˆë ¨ ì„¤ì • íŒŒì¼ ìƒì„±"""
        
        config_content = f"""# @package _global_
defaults:
  - _self_

name: "pure-volume-no-rotation-test"
description: "ìˆœìˆ˜ ë³¼ë¥¨ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ (íšŒì „ ì—†ìŒ) - 3x ë°°ìˆ˜"
tags: ["pure-volume", "no-rotation", "hypothesis-test", "3X"]

seed: 42
device: 'cuda'

# Pure Volume Dataset
data:
  root_dir: "{dataset_path}"
  csv_file: "{dataset_path}/metadata/train.csv"
  meta_file: "{dataset_path}/metadata/meta.csv"
  val_csv_file: "{dataset_path}/metadata/val.csv"
  val_root_dir: "{dataset_path}/val"
  
  image_size: 224
  val_size: 0.0  # ë³„ë„ validation íŒŒì¼ ì‚¬ìš©
  num_workers: 4
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]

# ëŸ°íƒ€ì„ ì¦ê°• ë¹„í™œì„±í™” (ë°ì´í„°ì— ì´ë¯¸ ì ìš©ë¨)
augmentation:
  enabled: false
  strategy: "none"
  intensity: 0.0

model:
  name: "resnet50"
  pretrained: true

train:
  epochs: 25  # ë” ë§ì€ ë°ì´í„°ë¡œ ì•ˆì •ì  í›ˆë ¨
  batch_size: 32  # ë” í° ë°°ì¹˜ í¬ê¸°
  mixed_precision: true
  
  early_stopping:
    patience: 8
    metric: 'val_f1'
    mode: 'max'

optimizer:
  name: 'AdamW'
  learning_rate: 0.0001
  weight_decay: 0.0001

scheduler:
  name: 'CosineAnnealingLR'
  T_max: 25

wandb:
  username: wchoi189
  enabled: true
  project: "document-classifier-pure-volume"
  name: "pure-volume-3X-no-rotation-test"
  tags: ["pure-volume", "no-rotation", "3X", "hypothesis-test"]
  notes: "ìˆœìˆ˜ ë³¼ë¥¨ ì¦ê°• í…ŒìŠ¤íŠ¸ - íšŒì „ ì—†ìŒìœ¼ë¡œ ê°€ì„¤ ê²€ì¦"

paths:
  output_dir: "outputs/pure_volume_test"
  model_dir: "outputs/pure_volume_test/models"

logging:
  checkpoint_dir: "outputs/pure_volume_test/checkpoints"
"""
        
        # ì„¤ì • íŒŒì¼ ì €ì¥
        config_path = Path("configs/experiment/pure_volume_no_rotation.yaml")
        config_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(config_content)
        
        ic(f"ğŸ“„ í›ˆë ¨ ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")
        return config_path


def main():
    """CLI ì§„ì…ì """
    fire.Fire(PureVolumeGenerator)


if __name__ == "__main__":
    main()