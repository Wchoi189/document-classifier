# src/data/csv_dataset.py - ENHANCED VERSION
"""
Enhanced CSV Document Dataset with Cross-Phase Validation Support
êµì°¨ ë‹¨ê³„ ê²€ì¦ì„ ì§€ì›í•˜ëŠ” í–¥ìƒëœ CSV ë¬¸ì„œ ë°ì´í„°ì…‹
"""

import os
import cv2
import pandas as pd
from torch.utils.data import Dataset
from sklearn.model_selection import train_test_split
from pathlib import Path
from icecream import ic


class CSVDocumentDataset(Dataset):
    """
    Enhanced Document dataset with cross-phase validation support
    êµì°¨ ë‹¨ê³„ ê²€ì¦ì„ ì§€ì›í•˜ëŠ” í–¥ìƒëœ ë¬¸ì„œ ë°ì´í„°ì…‹
    """
    
    def __init__(self, 
                 root_dir, 
                 csv_file, 
                 meta_file, 
                 transform=None, 
                 split='train', 
                 val_size=0.2, 
                 seed=42,
                 val_root_dir=None,
                 val_csv_file=None,
                 val_meta_file=None):
        """
        Args:
            root_dir: í›ˆë ¨ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì˜ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
            csv_file: í›ˆë ¨ CSV íŒŒì¼
            meta_file: ë©”íƒ€ë°ì´í„° íŒŒì¼
            transform: ì´ë¯¸ì§€ ë³€í™˜
            split: 'train', 'val', ë˜ëŠ” 'all'
            val_size: ê²€ì¦ ì„¸íŠ¸ ë¹„ìœ¨ (êµì°¨ ë‹¨ê³„ ê²€ì¦ ì‚¬ìš© ì‹œ ë¬´ì‹œë¨)
            seed: ëœë¤ ì‹œë“œ
            val_root_dir: ë³„ë„ ê²€ì¦ ë°ì´í„°ì…‹ì˜ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (êµì°¨ ë‹¨ê³„ìš©)
            val_csv_file: ë³„ë„ ê²€ì¦ CSV íŒŒì¼ (êµì°¨ ë‹¨ê³„ìš©)
            val_meta_file: ë³„ë„ ê²€ì¦ ë©”íƒ€ íŒŒì¼ (êµì°¨ ë‹¨ê³„ìš©, ì„ íƒì‚¬í•­)
        """
        self.transform = transform
        self.split = split
        
        # ğŸ”§ **í•µì‹¬ ìˆ˜ì •**: ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì¼ê´€ë˜ê²Œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì†ì„±
        self.image_dir = None
        
        self.is_cross_phase = val_csv_file is not None
        
        # ë©”íƒ€ë°ì´í„° ë¡œë“œ (í´ë˜ìŠ¤ ì •ë³´ëŠ” í›ˆë ¨ìš© ë©”íƒ€ íŒŒì¼ ê¸°ì¤€ìœ¼ë¡œ í†µì¼)
        self.meta_df = pd.read_csv(meta_file)
        self.target_to_class = dict(zip(self.meta_df['target'], self.meta_df['class_name']))
        self.classes = [self.target_to_class[i] for i in sorted(self.target_to_class.keys())]
        
        if self.is_cross_phase:
            ic("ğŸ”„ Cross-phase validation mode ê°ì§€ë¨")
            self._setup_cross_phase_validation(root_dir, csv_file, val_root_dir, val_csv_file)
        else:
            ic("ğŸ“Š Standard single-dataset validation mode")
            self._setup_standard_validation(root_dir, csv_file, val_size, seed)

        # ìµœì¢… ì„¤ì •ëœ ë°ì´í„°í”„ë ˆì„ê³¼ ê²½ë¡œë¡œ ê²€ì¦ ìˆ˜í–‰
        self._verify_dataset()
    
    def _setup_cross_phase_validation(self, train_root, train_csv, val_root, val_csv):
        """êµì°¨ ë‹¨ê³„ ê²€ì¦ ì„¤ì •"""
        if self.split == 'train':
            self.df = pd.read_csv(train_csv)
            # ğŸ”§ **ìˆ˜ì •**: 'train' í´ë”ê¹Œì§€ í¬í•¨í•œ ì „ì²´ ê²½ë¡œë¥¼ image_dirë¡œ ì„¤ì •
            self.image_dir = Path(train_root) / 'train'
            ic(f"âœ… í›ˆë ¨ ë°ì´í„° ë¡œë“œ: {len(self.df)}ê°œ ìƒ˜í”Œ, ê²½ë¡œ: {self.image_dir}")
        elif self.split == 'val':
            self.df = pd.read_csv(val_csv)
            # ğŸ”§ **ìˆ˜ì •**: 'val' í´ë”ê¹Œì§€ í¬í•¨í•œ ì „ì²´ ê²½ë¡œë¥¼ image_dirë¡œ ì„¤ì •
            self.image_dir = Path(val_root) / 'val'
            ic(f"ğŸ”„ êµì°¨ ë‹¨ê³„ ê²€ì¦ ë°ì´í„° ë¡œë“œ: {len(self.df)}ê°œ ìƒ˜í”Œ, ê²½ë¡œ: {self.image_dir}")
        else: # 'all'
            self.df = pd.read_csv(train_csv)
            self.image_dir = Path(train_root) / 'train'

    def _setup_standard_validation(self, root_dir, csv_file, val_size, seed):
        """í‘œì¤€ ë‹¨ì¼ ë°ì´í„°ì…‹ ê²€ì¦ ì„¤ì •"""
        full_df = pd.read_csv(csv_file)
        ic(f"í‘œì¤€ ë°ì´í„°ì…‹ ë¡œë“œ: {len(full_df)} ìƒ˜í”Œ")

        # ğŸ”§ **ìˆ˜ì •**: í‘œì¤€ ëª¨ë“œì—ì„œë„ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œëŠ” ë™ì¼
        self.image_dir = Path(root_dir) / 'train'

        if self.split in ['train', 'val'] and val_size > 0:
            train_df, val_df = train_test_split(
                full_df, 
                test_size=val_size, 
                random_state=seed, 
                stratify=full_df['target']
            )
            self.df = train_df if self.split == 'train' else val_df
        else:
            self.df = full_df

        ic(f"ìµœì¢… ë°ì´í„°ì…‹ í¬ê¸° ('{self.split}'): {len(self.df)}ê°œ ìƒ˜í”Œ, ê²½ë¡œ: {self.image_dir}")

    def _verify_dataset(self):
        """ë°ì´í„°ì…‹ ì„¤ì • ê²€ì¦ (ê²½ë¡œ ë° ìƒ˜í”Œ íŒŒì¼)"""
        if self.df.empty:
            ic("âš ï¸ ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆì–´ ê²€ì¦ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        ic("ğŸ” ë°ì´í„°ì…‹ ì„¤ì • í™•ì¸ ì¤‘...")
        sample_files = self.df['ID'].head(3).tolist()
        missing_count = 0
        
        for filename in sample_files:
            # ğŸ”§ **ìˆ˜ì •**: ì¼ê´€ëœ self.image_dir ì‚¬ìš©
            img_path = self.image_dir / filename
            if not img_path.exists():
                missing_count += 1
                ic(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {img_path}")
        
        if missing_count == 0:
            ic(f"âœ… ìƒ˜í”Œ íŒŒì¼ ê²€ì¦ ì™„ë£Œ ({len(sample_files)}ê°œ í™•ì¸)")
        else:
            ic(f"âš ï¸ {missing_count}/{len(sample_files)} ìƒ˜í”Œ íŒŒì¼ ëˆ„ë½")

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        
        # ğŸ”§ **ìˆ˜ì •**: ê²½ë¡œ êµ¬ì„± ë¡œì§ì„ self.image_dirë¡œ ë‹¨ìˆœí™”
        img_path = self.image_dir / row['ID']
        
        image = cv2.imread(str(img_path))
        if image is None:
            raise ValueError(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}")
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        if self.transform:
            augmented = self.transform(image=image)
            image = augmented['image']
        
        return image, row['target']

    def get_info(self):
        """ë°ì´í„°ì…‹ ì •ë³´ ë°˜í™˜"""
        return {
            'dataset_size': len(self.df),
            'num_classes': len(self.classes),
            'split': self.split,
            'is_cross_phase': self.is_cross_phase,
        }


# ğŸ”§ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜: êµì°¨ ë‹¨ê³„ ê²€ì¦ ê°ì§€
def is_cross_phase_config(config):
    """
    ì„¤ì •ì—ì„œ êµì°¨ ë‹¨ê³„ ê²€ì¦ ì‚¬ìš© ì—¬ë¶€ ê°ì§€
    
    Args:
        config: ë°ì´í„° ì„¤ì • ë”•ì…”ë„ˆë¦¬
        
    Returns:
        bool: êµì°¨ ë‹¨ê³„ ê²€ì¦ ì‚¬ìš© ì—¬ë¶€
    """
    data_config = config.get('data', {})
    return data_config.get('val_csv_file') is not None


def create_cross_phase_datasets(config, train_transforms, valid_transforms):
    """
    êµì°¨ ë‹¨ê³„ ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„± ìœ í‹¸ë¦¬í‹°
    
    Args:
        config: ì „ì²´ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        train_transforms: í›ˆë ¨ìš© ë³€í™˜
        valid_transforms: ê²€ì¦ìš© ë³€í™˜
        
    Returns:
        tuple: (train_dataset, val_dataset)
    """
    data_config = config['data']
    
    ic("ğŸ”„ êµì°¨ ë‹¨ê³„ ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
    
    # í›ˆë ¨ ë°ì´í„°ì…‹
    train_dataset = CSVDocumentDataset(
        root_dir=data_config['root_dir'],
        csv_file=data_config['csv_file'],
        meta_file=data_config['meta_file'],
        transform=train_transforms,
        split='train',
        val_size=0.0,  # êµì°¨ ë‹¨ê³„ì—ì„œëŠ” ë¶„í• í•˜ì§€ ì•ŠìŒ
        seed=config['seed'],
        val_root_dir=data_config.get('val_root_dir'),
        val_csv_file=data_config.get('val_csv_file'),
        val_meta_file=data_config.get('val_meta_file')
    )
    
    # ê²€ì¦ ë°ì´í„°ì…‹ (ë³„ë„ ë°ì´í„°)
    val_dataset = CSVDocumentDataset(
        root_dir=data_config['root_dir'],  # ê¸°ë³¸ê°’
        csv_file=data_config['csv_file'],   # ê¸°ë³¸ê°’
        meta_file=data_config['meta_file'],
        transform=valid_transforms,
        split='val',
        val_size=0.0,
        seed=config['seed'],
        val_root_dir=data_config.get('val_root_dir'),
        val_csv_file=data_config.get('val_csv_file'),
        val_meta_file=data_config.get('val_meta_file')
    )
    
    # ë°ì´í„°ì…‹ ì •ë³´ ì¶œë ¥
    train_info = train_dataset.get_info()
    val_info = val_dataset.get_info()
    
    ic(f"âœ… í›ˆë ¨ ë°ì´í„°ì…‹: {train_info['dataset_size']}ê°œ ìƒ˜í”Œ")
    ic(f"ğŸ”„ ê²€ì¦ ë°ì´í„°ì…‹: {val_info['dataset_size']}ê°œ ìƒ˜í”Œ (êµì°¨ ë‹¨ê³„)")
    
    return train_dataset, val_dataset