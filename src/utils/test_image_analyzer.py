"""
src/utils/test_image_analyzer.py

í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¶„ì„ê¸° - ê°€ì¥ ë„ì „ì ì´ê³  ëŒ€í‘œì ì¸ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìë™ ì‹ë³„
Test image analyzer - Automatically identify most challenging and representative test samples
"""

import os
import cv2
import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import json
from collections import defaultdict
import fire
from sklearn.cluster import KMeans
from scipy.spatial.distance import cdist

from src.utils.config_utils import load_config
import matplotlib.pyplot as plt
import matplotlib as mpl
from matplotlib.figure import Figure

# Set the font family to NanumGothic
mpl.rcParams['font.family'] = 'NanumGothic'
mpl.rcParams['axes.unicode_minus'] = False


class TestImageAnalyzer:
    """í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì˜ ë‚œì´ë„ì™€ íŠ¹ì„±ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ìƒ˜í”Œì„ ì„ íƒí•˜ëŠ” ë„êµ¬"""
    
    def __init__(self, config_path: str = "configs/config.yaml"):
        """
        ì´ˆê¸°í™”
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.config = load_config(config_path)
        self.setup_paths()
        
    def setup_paths(self):
        """ê²½ë¡œ ì„¤ì •"""
        self.data_dir = Path(self.config['data']['root_dir'])
        self.test_dir = self.data_dir / 'test'
        self.train_dir = self.data_dir / 'train'
        self.output_dir = Path('outputs/test_image_analysis')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"âœ… í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬: {self.test_dir}")
        print(f"âœ… í›ˆë ¨ ë””ë ‰í† ë¦¬: {self.train_dir}")
        print(f"âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥: {self.output_dir}")
    
    def analyze_image_quality(self, image_path: str) -> Dict:
        """ì´ë¯¸ì§€ í’ˆì§ˆ ë¶„ì„ - ë¸”ëŸ¬, ë°ê¸°, ëŒ€ë¹„ ë“±"""
        img = cv2.imread(image_path)
        if img is None:
            return {}
        
        # RGBë¡œ ë³€í™˜
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # 1. ë¸”ëŸ¬ ì •ë„ ì¸¡ì • (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
        blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        # 2. ë°ê¸° ë¶„ì„
        brightness = np.mean(img_rgb)
        brightness_std = np.std(img_rgb)
        
        # 3. ëŒ€ë¹„ ë¶„ì„ (RMS ëŒ€ë¹„)
        contrast = gray.std()
        
        # 4. ìƒ‰ìƒ ë¶„í¬ ë¶„ì„
        hist_b = cv2.calcHist([img], [0], None, [256], [0, 256])
        hist_g = cv2.calcHist([img], [1], None, [256], [0, 256])
        hist_r = cv2.calcHist([img], [2], None, [256], [0, 256])
        
        # íˆìŠ¤í† ê·¸ë¨ ì—”íŠ¸ë¡œí”¼ (ìƒ‰ìƒ ë‹¤ì–‘ì„±)
        hist_combined = np.concatenate([hist_b, hist_g, hist_r])
        hist_normalized = hist_combined / (hist_combined.sum() + 1e-7)
        color_entropy = -np.sum(hist_normalized * np.log(hist_normalized + 1e-7))
        
        # 5. ê°€ì¥ìë¦¬ ë°€ë„
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / (gray.shape[0] * gray.shape[1])
        
        return {
            'blur_score': float(blur_score),
            'brightness': float(brightness),
            'brightness_std': float(brightness_std),
            'contrast': float(contrast),
            'color_entropy': float(color_entropy),
            'edge_density': float(edge_density),
            'width': img.shape[1],
            'height': img.shape[0],
            'aspect_ratio': img.shape[1] / img.shape[0]
        }
    
    def detect_perspective_distortion(self, image_path: str) -> Dict:
        """ì›ê·¼ ì™œê³¡ ì •ë„ ê°ì§€"""
        img = cv2.imread(image_path)
        if img is None:
            return {}
        
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # 1. í—ˆí”„ ë³€í™˜ìœ¼ë¡œ ì§ì„  ê°ì§€
        edges = cv2.Canny(gray, 50, 150, apertureSize=3)
        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)
        
        line_angles = []
        if lines is not None:
            for rho, theta in lines[:20]:  # ìƒìœ„ 20ê°œ ì§ì„ ë§Œ ë¶„ì„
                angle = theta * 180 / np.pi
                line_angles.append(angle)
        
        # 2. ê°ë„ ë¶„ì‚° (ë†’ì„ìˆ˜ë¡ ë” ì™œê³¡ë¨)
        angle_variance = np.var(line_angles) if line_angles else 0
        
        # 3. ì£¼ìš” ë°©í–¥ì„± ë¶„ì„ (0ë„, 90ë„ì—ì„œ ì–¼ë§ˆë‚˜ ë²—ì–´ë‚¬ëŠ”ì§€)
        if line_angles:
            # ìˆ˜ì§/ìˆ˜í‰ì—ì„œì˜ í¸ì°¨
            horizontal_deviation = min([abs(angle) for angle in line_angles if abs(angle) < 45], default=45)
            vertical_deviation = min([abs(angle - 90) for angle in line_angles if abs(angle - 90) < 45], default=45)
            perspective_score = min(horizontal_deviation, vertical_deviation)
        else:
            perspective_score = 0
        
        return {
            'line_count': len(line_angles),
            'angle_variance': float(angle_variance),
            'perspective_score': float(perspective_score),  # ë‚®ì„ìˆ˜ë¡ ë” ì •ì§í•œ ë¬¸ì„œ
            'has_strong_lines': len(line_angles) > 10
        }
    
    def analyze_document_structure(self, image_path: str) -> Dict:
        """ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ - í…ìŠ¤íŠ¸ ì˜ì—­, ì—¬ë°± ë“±"""
        img = cv2.imread(image_path)
        if img is None:
            return {}
        
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        h, w = gray.shape
        
        # 1. í…ìŠ¤íŠ¸ ì˜ì—­ ì¶”ì • (ì–´ë‘ìš´ ì˜ì—­ = í…ìŠ¤íŠ¸)
        # ì ì‘í˜• ì„ê³„ê°’ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì˜ì—­ ë¶„ë¦¬
        adaptive_thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                              cv2.THRESH_BINARY, 11, 2)
        text_pixels = np.sum(adaptive_thresh == 0)  # ê²€ì€ìƒ‰ í”½ì…€ = í…ìŠ¤íŠ¸
        text_ratio = text_pixels / (h * w)
        
        # 2. ì—¬ë°± ë¶„ì„ (ê°€ì¥ìë¦¬ ì˜ì—­ì˜ ë°ê¸°)
        border_size = min(w, h) // 20  # ì´ë¯¸ì§€ í¬ê¸°ì˜ 5%
        top_border = np.mean(gray[:border_size, :])
        bottom_border = np.mean(gray[-border_size:, :])
        left_border = np.mean(gray[:, :border_size])
        right_border = np.mean(gray[:, -border_size:])
        avg_border_brightness = np.mean([top_border, bottom_border, left_border, right_border])
        
        # 3. ì¤‘ì•™ vs ê°€ì¥ìë¦¬ ë°ê¸° ì°¨ì´
        center_region = gray[h//4:3*h//4, w//4:3*w//4]
        center_brightness = np.mean(center_region)
        brightness_contrast = abs(center_brightness - avg_border_brightness)
        
        # 4. ìˆ˜í‰/ìˆ˜ì§ íˆ¬ì˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë¼ì¸ ê°ì§€
        horizontal_projection = np.sum(adaptive_thresh == 0, axis=1)
        vertical_projection = np.sum(adaptive_thresh == 0, axis=0)
        
        # í…ìŠ¤íŠ¸ ë¼ì¸ ìˆ˜ ì¶”ì • (í”¼í¬ ê°ì§€)
        from scipy.signal import find_peaks
        peaks_h, _ = find_peaks(horizontal_projection, height=w*0.05)  # ìµœì†Œ ë†’ì´ ì¡°ê±´
        estimated_text_lines = len(peaks_h)
        
        return {
            'text_ratio': float(text_ratio),
            'avg_border_brightness': float(avg_border_brightness),
            'center_brightness': float(center_brightness),
            'brightness_contrast': float(brightness_contrast),
            'estimated_text_lines': int(estimated_text_lines),
            'document_completeness': float(min(1.0, text_ratio * 2))  # ë¬¸ì„œ ì™„ì„±ë„ ì¶”ì •
        }
    
    def calculate_challenge_score(self, image_analysis: Dict) -> float:
        """ì´ë¯¸ì§€ì˜ ë„ì „ì  ì •ë„ë¥¼ 0-1 ìŠ¤ì¼€ì¼ë¡œ ê³„ì‚°"""
        score_components = []
        
        # 1. ë¸”ëŸ¬ ì ìˆ˜ (ë‚®ì„ìˆ˜ë¡ ë” ë„ì „ì )
        blur_score = image_analysis.get('blur_score', 100)
        blur_challenge = max(0, (100 - blur_score) / 100)  # 100 ì´í•˜ì¼ ë•Œ ë„ì „ì 
        score_components.append(blur_challenge * 0.2)
        
        # 2. ë°ê¸° ê·¹ê°’ (ë„ˆë¬´ ì–´ë‘¡ê±°ë‚˜ ë°ìœ¼ë©´ ë„ì „ì )
        brightness = image_analysis.get('brightness', 128)
        brightness_challenge = abs(brightness - 128) / 128  # 128ì—ì„œ ë©€ìˆ˜ë¡ ë„ì „ì 
        score_components.append(brightness_challenge * 0.15)
        
        # 3. ëŒ€ë¹„ (ë„ˆë¬´ ë‚®ìœ¼ë©´ ë„ì „ì )
        contrast = image_analysis.get('contrast', 50)
        contrast_challenge = max(0, (50 - contrast) / 50)
        score_components.append(contrast_challenge * 0.15)
        
        # 4. ì›ê·¼ ì™œê³¡ (ë†’ì„ìˆ˜ë¡ ë„ì „ì )
        perspective_score = image_analysis.get('perspective_score', 0)
        perspective_challenge = min(1.0, perspective_score / 30)  # 30ë„ ì´ìƒì´ë©´ ìµœëŒ€ ë„ì „ì 
        score_components.append(perspective_challenge * 0.25)
        
        # 5. ë¬¸ì„œ ì™„ì„±ë„ (ë‚®ì„ìˆ˜ë¡ ë„ì „ì )
        completeness = image_analysis.get('document_completeness', 1.0)
        completeness_challenge = 1.0 - completeness
        score_components.append(completeness_challenge * 0.15)
        
        # 6. í…ìŠ¤íŠ¸ ë¹„ìœ¨ (ë„ˆë¬´ ë‚®ê±°ë‚˜ ë†’ìœ¼ë©´ ë„ì „ì )
        text_ratio = image_analysis.get('text_ratio', 0.5)
        optimal_text_ratio = 0.3  # ìµœì  í…ìŠ¤íŠ¸ ë¹„ìœ¨
        text_challenge = abs(text_ratio - optimal_text_ratio) / optimal_text_ratio
        score_components.append(min(1.0, text_challenge) * 0.1)
        
        total_challenge_score = sum(score_components)
        return min(1.0, total_challenge_score)
    
    def analyze_all_test_images(self) -> pd.DataFrame:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¶„ì„"""
        print("ğŸ” ëª¨ë“  í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
        
        test_files = list(self.test_dir.glob('*.jpg')) + list(self.test_dir.glob('*.png'))
        
        if not test_files:
            raise FileNotFoundError(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.test_dir}")
        
        results = []
        
        for i, img_path in enumerate(test_files):
            if i % 50 == 0:  # ì§„í–‰ ìƒí™© ì¶œë ¥
                print(f"   ì§„í–‰: {i}/{len(test_files)}")
            
            try:
                # ê¸°ë³¸ ì´ë¯¸ì§€ ë¶„ì„
                quality_analysis = self.analyze_image_quality(str(img_path))
                perspective_analysis = self.detect_perspective_distortion(str(img_path))
                structure_analysis = self.analyze_document_structure(str(img_path))
                
                # ëª¨ë“  ë¶„ì„ ê²°ê³¼ ê²°í•©
                combined_analysis = {
                    'filename': img_path.name,
                    'file_path': str(img_path),
                    **quality_analysis,
                    **perspective_analysis,
                    **structure_analysis
                }
                
                # ë„ì „ ì ìˆ˜ ê³„ì‚°
                combined_analysis['challenge_score'] = self.calculate_challenge_score(combined_analysis)
                
                results.append(combined_analysis)
                
            except Exception as e:
                print(f"âš ï¸ ë¶„ì„ ì‹¤íŒ¨: {img_path.name} - {e}")
                continue
        
        df_results = pd.DataFrame(results)
        print(f"âœ… {len(df_results)}ê°œ ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ")
        
        return df_results
    
    def select_representative_samples(self, df_analysis: pd.DataFrame, 
                                    n_samples: int = 20) -> pd.DataFrame:
        """ëŒ€í‘œì ì¸ ìƒ˜í”Œ ì„ íƒ (ë‹¤ì–‘í•œ ë‚œì´ë„ì™€ íŠ¹ì„±ì„ ê³ ë ¤)"""
        print(f"ğŸ¯ ëŒ€í‘œ ìƒ˜í”Œ {n_samples}ê°œ ì„ íƒ ì¤‘...")
        
        selected_samples = []
        
        # 1. ë„ì „ì  ë‚œì´ë„ë³„ ìƒ˜í”Œ (40%)
        challenge_samples = int(n_samples * 0.4)
        
        # ë§¤ìš° ë„ì „ì  (ìƒìœ„ 20%)
        very_challenging = df_analysis.nlargest(len(df_analysis)//5, 'challenge_score')
        selected_samples.extend(very_challenging.sample(min(challenge_samples//2, len(very_challenging))).to_dict('records'))
        
        # ì¤‘ê°„ ë„ì „ì  (ì¤‘ê°„ 30%)
        medium_challenging = df_analysis[(df_analysis['challenge_score'] >= df_analysis['challenge_score'].quantile(0.35)) & 
                                       (df_analysis['challenge_score'] <= df_analysis['challenge_score'].quantile(0.65))]
        selected_samples.extend(medium_challenging.sample(min(challenge_samples//2, len(medium_challenging))).to_dict('records'))
        
        # 2. íŠ¹ì • ë¬¸ì œ ìœ í˜•ë³„ ìƒ˜í”Œ (60%)
        remaining_samples = n_samples - len(selected_samples)
        
        # ë¸”ëŸ¬ ë¬¸ì œ
        blurry_samples = df_analysis.nsmallest(len(df_analysis)//4, 'blur_score')
        if len(blurry_samples) > 0:
            selected_samples.extend(blurry_samples.sample(min(2, len(blurry_samples))).to_dict('records'))
        
        # ë°ê¸° ë¬¸ì œ (ë„ˆë¬´ ì–´ë‘¡ê±°ë‚˜ ë°ìŒ)
        brightness_issues = df_analysis[(df_analysis['brightness'] < 80) | (df_analysis['brightness'] > 180)]
        if len(brightness_issues) > 0:
            selected_samples.extend(brightness_issues.sample(min(2, len(brightness_issues))).to_dict('records'))
        
        # ì›ê·¼ ì™œê³¡ ë¬¸ì œ
        perspective_issues = df_analysis.nlargest(len(df_analysis)//4, 'perspective_score')
        if len(perspective_issues) > 0:
            selected_samples.extend(perspective_issues.sample(min(3, len(perspective_issues))).to_dict('records'))
        
        # ë¬¸ì„œ ë¶ˆì™„ì „ì„± ë¬¸ì œ
        incomplete_docs = df_analysis.nsmallest(len(df_analysis)//4, 'document_completeness')
        if len(incomplete_docs) > 0:
            selected_samples.extend(incomplete_docs.sample(min(2, len(incomplete_docs))).to_dict('records'))
        
        # ë‚˜ë¨¸ì§€ëŠ” ëœë¤ ë‹¤ì–‘ì„± í™•ë³´
        already_selected = {s['filename'] for s in selected_samples}
        remaining_df = df_analysis[~df_analysis['filename'].isin(already_selected)]
        if len(remaining_df) > 0 and len(selected_samples) < n_samples:
            additional_needed = n_samples - len(selected_samples)
            selected_samples.extend(remaining_df.sample(min(additional_needed, len(remaining_df))).to_dict('records'))
        
        # ì¤‘ë³µ ì œê±° ë° ìµœì¢… ì„ íƒ
        unique_samples = []
        seen_filenames = set()
        
        for sample in selected_samples:
            if sample['filename'] not in seen_filenames:
                unique_samples.append(sample)
                seen_filenames.add(sample['filename'])
            
            if len(unique_samples) >= n_samples:
                break
        
        result_df = pd.DataFrame(unique_samples)
        print(f"âœ… {len(result_df)}ê°œ ëŒ€í‘œ ìƒ˜í”Œ ì„ íƒ ì™„ë£Œ")
        
        return result_df
    def create_sample_gallery(self, selected_samples: pd.DataFrame) -> Figure:
        """ì„ íƒëœ ìƒ˜í”Œë“¤ì˜ ê°¤ëŸ¬ë¦¬ ìƒì„±"""
        """ì„ íƒëœ ìƒ˜í”Œë“¤ì˜ ê°¤ëŸ¬ë¦¬ ìƒì„±"""
        n_samples = len(selected_samples)
        n_cols = 5
        n_rows = (n_samples + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 4 * n_rows))
        if n_rows == 1:
            axes = axes.reshape(1, -1)
        
        for i, (idx, sample) in enumerate(selected_samples.iterrows()):
            if i >= n_rows * n_cols:
                break
                
            row, col = i // n_cols, i % n_cols
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            img = cv2.imread(sample['file_path'])
            if img is not None:
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                axes[row, col].imshow(img)
                
                # ì œëª© ì„¤ì • (ì£¼ìš” íŠ¹ì„± í‘œì‹œ)
                title = f"{sample['filename']}\n"
                title += f"ë„ì „ì ìˆ˜: {sample['challenge_score']:.2f}\n"
                title += f"ë¸”ëŸ¬: {sample['blur_score']:.0f}, "
                title += f"ì›ê·¼: {sample['perspective_score']:.0f}"
                
                axes[row, col].set_title(title, fontsize=9)
            else:
                axes[row, col].text(0.5, 0.5, 'Load\nError', 
                                  ha='center', va='center', transform=axes[row, col].transAxes)
            
            axes[row, col].axis('off')
        
        # ë¹ˆ subplotë“¤ ìˆ¨ê¸°ê¸°
        for i in range(n_samples, n_rows * n_cols):
            row, col = i // n_cols, i % n_cols
            axes[row, col].axis('off')
        
        plt.suptitle('ì„ íƒëœ ëŒ€í‘œ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œë“¤', fontsize=16)
        plt.tight_layout()
        return fig
    
    def generate_selection_report(self, analysis_df: pd.DataFrame, 
                                selected_df: pd.DataFrame) -> str:
        """ì„ íƒ ë³´ê³ ì„œ ìƒì„±"""
        report_path = self.output_dir / 'test_image_selection_report.txt'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì„ íƒ ë³´ê³ ì„œ\n")
            f.write("=" * 50 + "\n\n")
            
            f.write(f"## ì „ì²´ ë¶„ì„ ê²°ê³¼\n")
            f.write(f"- ì „ì²´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(analysis_df)}ê°œ\n")
            f.write(f"- ì„ íƒëœ ëŒ€í‘œ ìƒ˜í”Œ: {len(selected_df)}ê°œ\n\n")
            
            f.write(f"## ë„ì „ ì ìˆ˜ ë¶„í¬\n")
            f.write(f"- í‰ê·  ë„ì „ ì ìˆ˜: {analysis_df['challenge_score'].mean():.3f}\n")
            f.write(f"- ìµœê³  ë„ì „ ì ìˆ˜: {analysis_df['challenge_score'].max():.3f}\n")
            f.write(f"- ìµœì € ë„ì „ ì ìˆ˜: {analysis_df['challenge_score'].min():.3f}\n\n")
            
            f.write(f"## ì„ íƒëœ ìƒ˜í”Œì˜ íŠ¹ì„±\n")
            f.write(f"- í‰ê·  ë„ì „ ì ìˆ˜: {selected_df['challenge_score'].mean():.3f}\n")
            f.write(f"- ë¸”ëŸ¬ ë¬¸ì œ ìƒ˜í”Œ: {len(selected_df[selected_df['blur_score'] < 50])}ê°œ\n")
            f.write(f"- ì›ê·¼ ì™œê³¡ ìƒ˜í”Œ: {len(selected_df[selected_df['perspective_score'] > 10])}ê°œ\n")
            f.write(f"- ë°ê¸° ë¬¸ì œ ìƒ˜í”Œ: {len(selected_df[(selected_df['brightness'] < 80) | (selected_df['brightness'] > 180)])}ê°œ\n\n")
            
            f.write(f"## ì„ íƒëœ íŒŒì¼ ëª©ë¡\n")
            for idx, sample in selected_df.iterrows():
                f.write(f"- {sample['filename']}: ë„ì „ì ìˆ˜ {sample['challenge_score']:.3f}\n")
            
            f.write(f"\n## ì‚¬ìš© ë°©ë²•\n")
            f.write(f"1. ì´ íŒŒì¼ë“¤ì„ ì‹œê°ì  ê²€ì¦ì— í™œìš©\n")
            f.write(f"2. ì¦ê°• ê¸°ë²•ì˜ íš¨ê³¼ë¥¼ ì´ ìƒ˜í”Œë“¤ë¡œ í…ŒìŠ¤íŠ¸\n")
            f.write(f"3. ëª¨ë¸ ì„±ëŠ¥ ê°œì„  ì‹œ ì´ ìƒ˜í”Œë“¤ë¡œ ê²€ì¦\n")
        
        return str(report_path)
    
    def run_comprehensive_analysis(self, n_samples: int = 20):
        """ì¢…í•© í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ ì¢…í•© í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘...")
        
        # 1. ëª¨ë“  í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¶„ì„
        analysis_df = self.analyze_all_test_images()
        
        # 2. ëŒ€í‘œ ìƒ˜í”Œ ì„ íƒ
        selected_df = self.select_representative_samples(analysis_df, n_samples)
        
        # 3. ê²°ê³¼ ì €ì¥
        analysis_path = self.output_dir / 'full_test_analysis.csv'
        analysis_df.to_csv(analysis_path, index=False)
        
        selected_path = self.output_dir / 'selected_representative_samples.csv'
        selected_df.to_csv(selected_path, index=False)
        
        # 4. ê°¤ëŸ¬ë¦¬ ìƒì„±
        print("ğŸ–¼ï¸ ì„ íƒëœ ìƒ˜í”Œ ê°¤ëŸ¬ë¦¬ ìƒì„± ì¤‘...")
        gallery_fig = self.create_sample_gallery(selected_df)
        gallery_path = self.output_dir / 'representative_samples_gallery.png'
        gallery_fig.savefig(gallery_path, dpi=300, bbox_inches='tight')
        plt.close(gallery_fig)
        
        # 5. ë³´ê³ ì„œ ìƒì„±
        report_path = self.generate_selection_report(analysis_df, selected_df)
        
        print("\nâœ… ì¢…í•© ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“Š ì „ì²´ ë¶„ì„: {analysis_path}")
        print(f"ğŸ¯ ì„ íƒëœ ìƒ˜í”Œ: {selected_path}")
        print(f"ğŸ–¼ï¸ ê°¤ëŸ¬ë¦¬: {gallery_path}")
        print(f"ğŸ“„ ë³´ê³ ì„œ: {report_path}")
        
        return {
            'full_analysis': str(analysis_path),
            'selected_samples': str(selected_path),
            'gallery': str(gallery_path),
            'report': report_path
        }


def main():
    """ë©”ì¸ í•¨ìˆ˜ - Fire CLI ì¸í„°í˜ì´ìŠ¤"""
    fire.Fire(TestImageAnalyzer)


if __name__ == "__main__":
    main()