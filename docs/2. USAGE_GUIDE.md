# 📖 문서 분류 모델 종합 사용법 가이드

## 🏗️ 프로젝트 개요

**현재 상태**: 93% 테스트 정확도 (99% 훈련) - 6% 도메인 갭
**클래스**: 17개 문서 유형, 2.2:1 클래스 불균형
**핵심 발견**: 훈련/테스트 데이터 간 554% 회전 각도 차이
**프레임워크**: PyTorch + Hydra + WandB

---

## 📁 주요 파일 구조

```
📦 프로젝트 루트
├── 📁 configs/                    # 설정 파일
│   ├── config.yaml                # 메인 설정
│   └── 📁 experiment/             # 실험별 설정
├── 📁 scripts/                    # 실행 스크립트
│   ├── train.py                   # 훈련 스크립트
│   ├── predict.py                 # 예측 스크립트
│   ├── generate_datasets.py       # 데이터셋 생성
│   └── analyze_data.py            # 데이터 분석
├── 📁 src/
│   ├── 📁 analysis/               # 분석 도구
│   ├── 📁 data/                   # 데이터 처리
│   ├── 📁 training/               # 훈련 도구
│   ├── 📁 utils/                  # 유틸리티
│   └── 📁 inference/              # 추론 도구
└── 📁 outputs/                    # 결과 저장
    ├── 📁 models/                 # 훈련된 모델
    ├── 📁 predictions/            # 예측 결과
    └── 📁 analysis/               # 분석 결과
```

---

## 🚀 기본 사용법

### 1. 모델 훈련

#### 빠른 디버그 훈련 (3 에포크)
```bash
python scripts/train.py experiment=quick_debug --config-path=configs/experiment/quick_test.yaml
```

#### 프로덕션 훈련
```bash
python scripts/train.py experiment=production_robust
```

#### 커스텀 설정으로 훈련
```bash
python scripts/train.py model.name=resnet50 train.epochs=20 train.batch_size=32
```

```bash
# Config location 설정은 `scripts/train.py`에서 변경 가능
@hydra.main(version_base="1.2", config_path="../configs")

```
```bash
# 명시적으로 설정 파일 위치와 이름 정의
python scripts/train.py --config-path=/home/wb2x/document-classifier/configs --config-name=quick_debug
```

```bash
# 또는 상대적인 경로 사용
python scripts/train.py --config-path=../configs --config-name=quick_debug
```




### 2. 예측 생성

#### 최신 모델로 예측
```bash
python scripts/predict.py run --input_path data/raw/test --use-last
```

#### 특정 체크포인트로 예측
```bash
python scripts/predict.py run --input_path data/raw/test --checkpoint outputs/models/best_model.pth
```

#### WandB 로깅과 함께 예측
```bash
python scripts/predict.py predict_with_wandb outputs/models/best_model.pth data/raw/test --wandb-project document-classifier
```

---

## 🔍 분석 도구 사용법

### 1. Corruption 분석기 (데이터 도메인 갭 분석)
```bash
# 종합 corruption 분석 실행
python -m src.analysis.corruption_analyzer run_comprehensive_analysis

# 최대 샘플 수 지정
python -m src.analysis.corruption_analyzer run_comprehensive_analysis --max_samples 500
```

**결과 위치**: `outputs/corruption_analysis/`
- 훈련/테스트 데이터 간 차이점 분석
- 회전, 밝기, 블러, 노이즈 차이 시각화
- **핵심 발견**: 554% 회전 각도 차이

### 2. 클래스 성능 분석기
```bash
# 최신 예측 결과로 분석
python -m src.analysis.class_performance_analyzer run_comprehensive_analysis \
    --predictions_csv outputs/predictions/predictions_HHMM.csv

# 특정 예측 파일로 분석
python -m src.analysis.class_performance_analyzer run_comprehensive_analysis \
    --predictions_csv /path/to/your/predictions.csv
```

**결과 위치**: `outputs/class_performance_analysis/`
- 클래스별 정확도, F1 점수 분석
- 취약한 클래스 식별
- Corruption과 성능 연관성 분석

### 3. 오분류 분석기
```bash
# 종합 오분류 분석
python -m src.analysis.wrong_predictions_explorer analyze_predictions \
    --predictions_csv outputs/predictions/predictions_HHMM.csv

# HTML 보고서 생성
python -m src.analysis.wrong_predictions_explorer generate_html_report \
    --predictions_csv outputs/predictions/predictions_HHMM.csv
```

**결과 위치**: `outputs/wrong_predictions_analysis/`
- 오분류 패턴 시각화
- 클래스별 혼동 매트릭스
- 상세 HTML 보고서

### 4. 시각적 검증 도구
```bash
# 증강 전략 비교
python -m src.utils.visual_verification compare_augmentation_strategies

# 훈련/테스트 조건 비교
python -m src.utils.visual_verification compare_train_test_conditions

# 특정 샘플 분석
python -m src.utils.visual_verification analyze_samples --max_samples 50
```

**결과 위치**: `outputs/visual_verification/`
- 증강된 훈련 이미지 vs 실제 테스트 조건
- 증강 강도 시각적 검증

### 5. 테스트 이미지 분석기
```bash
# 종합 테스트 분석
python -m src.utils.test_image_analyzer run_comprehensive_analysis

# 대표 샘플 선택
python -m src.utils.test_image_analyzer select_representative_samples --num_samples 100
```

**결과 위치**: `outputs/test_image_analysis/`
- 테스트 데이터 특성 분석
- 대표 샘플 갤러리 생성

---

## 📊 데이터셋 생성 도구

### 1. 점진적 증강 데이터셋 생성
```bash
# 기본 점진적 데이터셋 (10배 증강)
python scripts/generate_datasets.py generate_progressive --multiplier=10

# 커스텀 배수로 생성
python scripts/generate_datasets.py generate_progressive --multiplier=15
```

**생성되는 데이터셋**:
- `phase1_mild_20deg`: ±20° 회전 (적응 단계)
- `phase2_variety_60deg`: ±60° + 이산 90° (다양성 단계)
- `phase3_full_90deg`: ±90° + 플립 (완전 견고성)

### 2. K-Fold 교차검증 데이터셋 생성
```bash
# 5-fold 데이터셋 생성
python scripts/generate_datasets.py generate_kfold --k=5 --multiplier=5 --strategy=phase1_mild

# 다른 전략으로 생성
python scripts/generate_datasets.py generate_kfold --k=5 --multiplier=10 --strategy=phase2_variety
```

**전략 옵션**:
- `phase1_mild`: 가벼운 증강 (±20°)
- `phase2_variety`: 중간 증강 (±60°)
- `phase3_full`: 완전 증강 (±90°)

### 3. 단일 데이터셋 생성
```bash
# 볼륨 중심 전략
python scripts/generate_datasets.py generate_single \
    --dataset_name=test_experiment \
    --strategy=volume_focused \
    --multiplier=5

# 테스트 조건 중심 전략
python scripts/generate_datasets.py generate_single \
    --dataset_name=test_focused \
    --strategy=test_focused \
    --multiplier=8
```

---

## 🧪 고급 훈련 도구

### 1. 보수적 증강 테스터
```bash
# 기본 보수적 테스트 (3 에포크)
python -m src.training.conservative_augmentation_tester run_conservative_augmentation_test \
    --baseline_checkpoint outputs/models/best_model.pth

# 더 긴 검증 (5 에포크)
python -m src.training.conservative_augmentation_tester run_conservative_augmentation_test \
    --baseline_checkpoint outputs/models/best_model.pth \
    --quick_epochs 5
```

**기능**:
- 기존 성능 유지하며 안전한 증강 테스트
- 5단계 점진적 증강 검증 (±0° → ±10° → ±15° → ±25° → ±45°)
- 각 단계별 성능 비교 및 권장사항 생성

**결과 위치**: `outputs/conservative_augmentation_test/`

### 2. 점진적 훈련 파이프라인
```bash
# Phase 1 훈련 (K-fold로)
python scripts/train.py experiment=phase1_kfold_training

# Phase 2 훈련 (체크포인트 로딩)
python scripts/train.py experiment=phase2_progressive load_checkpoint=outputs/models/phase1_best.pth

# Phase 3 최종 훈련
python scripts/train.py experiment=phase3_final load_checkpoint=outputs/models/phase2_best.pth
```

---

## 🎯 종합 데이터 분석 파이프라인

### 전체 분석 파이프라인 실행
```bash
# 모든 분석 도구를 순차적으로 실행
python scripts/analyze_data.py run_comprehensive_analysis

# 특정 예측 파일로 분석
python scripts/analyze_data.py run_comprehensive_analysis \
    --predictions_csv outputs/predictions/predictions_1234.csv
```

**실행되는 분석**:
1. 테스트 이미지 분석
2. 시각적 검증
3. 오분류 분석 (예측 파일 있는 경우)
4. 종합 보고서 생성

**결과**: `outputs/comprehensive_data_analysis/data_analysis_summary.md`

---

## 📈 WandB 모니터링

### 1. WandB 설정
```bash
# 환경 변수 설정
export WANDB_MODE=online  # 또는 offline, disabled
export WANDB_PROJECT=document-classifier
```

### 2. 훈련 중 WandB 로깅 확인 사항
- 훈련/검증 손실 및 정확도
- 샘플 예측 이미지
- 혼동 매트릭스
- 모델 가중치 히스토그램
- 하이퍼파라미터 추적

### 3. 예측 결과 WandB 업로드
```bash
python -m src.inference.wandb_predict predict_with_wandb_logging \
    outputs/models/best_model.pth data/raw/test \
    --wandb_project document-classifier
```

---

## 🔧 설정 파일 커스터마이징

### 메인 설정 파일 (`configs/config.yaml`)
```yaml
# 모델 설정
model:
  name: resnet50
  pretrained: true
  num_classes: 17

# 훈련 설정
train:
  epochs: 50
  batch_size: 32
  learning_rate: 0.001

# 데이터 설정
data:
  root_dir: data/raw
  image_size: 224
  batch_size: 32

# 증강 설정
augmentation:
  enabled: true
  strategy: robust
  intensity: 0.7

# WandB 설정
wandb:
  enabled: true
  project: document-classifier
  log_images: true
```

### 실험별 설정 (`configs/experiment/`)
- `quick_debug.yaml`: 빠른 디버깅 (3 에포크)
- `production_robust.yaml`: 프로덕션 훈련 (50 에포크)
- `phase1_kfold_training.yaml`: Phase 1 K-fold 훈련
- `phase2_progressive.yaml`: Phase 2 점진적 훈련

---

## 📊 결과 파일 위치 및 해석

### 모델 파일
- `outputs/models/best_model.pth`: 최고 성능 모델
- `outputs/models/last_model.pth`: 마지막 에포크 모델
- `outputs/models/phase1_best.pth`: Phase 1 최고 모델

### 예측 결과
- `outputs/predictions/predictions_HHMM.csv`: 예측 결과 (시간별)
  - 컬럼: `filename`, `predicted_class`, `confidence`, `predicted_target`

### 분석 결과
- `outputs/corruption_analysis/`: Corruption 분석 결과
- `outputs/class_performance_analysis/`: 클래스별 성능 분석
- `outputs/wrong_predictions_analysis/`: 오분류 분석
- `outputs/visual_verification/`: 시각적 검증 결과

### 생성된 데이터셋
- `data/augmented_datasets/`: 증강된 훈련 데이터셋
- `data/kfold_datasets/`: K-fold 교차검증 데이터셋

---

## 🚨 문제 해결 가이드

### 일반적인 오류와 해결방법

#### 1. 메모리 부족 오류
```bash
# 배치 크기 줄이기
python scripts/train.py train.batch_size=16

# 데이터 로더 워커 수 줄이기
python scripts/train.py data.num_workers=2
```

#### 2. CUDA 오류
```bash
# CPU로 강제 실행
python scripts/train.py device=cpu

# GPU 메모리 정리
python -c "import torch; torch.cuda.empty_cache()"
```

#### 3. 설정 파일 오류
```bash
# 설정 구조 확인
python -c "from src.utils.config_utils import load_config; print(load_config('configs/config.yaml'))"

# 기본 설정으로 초기화
cp configs/config.yaml.backup configs/config.yaml
```

#### 4. WandB 연결 문제
```bash
# 오프라인 모드로 전환
export WANDB_MODE=offline

# WandB 재로그인
wandb login
```

---

## 📝 모범 사례

### 1. 실험 추적
- 각 실험마다 명확한 이름과 설명 사용
- WandB 태그로 실험 그룹화
- 중요한 설정 변경사항 기록

### 2. 성능 개선 워크플로우
1. **기준점 설정**: 현재 79% 성능 확인
2. **문제 분석**: Corruption 분석으로 원인 파악
3. **점진적 개선**: 보수적 증강 테스터로 안전한 개선
4. **본격 훈련**: 검증된 설정으로 풀 훈련
5. **성능 검증**: 다양한 분석 도구로 검증

### 3. 데이터 관리
- 증강 데이터셋은 용량이 크므로 필요시에만 생성
- K-fold 검증으로 과적합 방지
- 대표 샘플을 통한 지속적 모니터링

---

## 🎯 다음 단계 권장사항

### 즉시 실행 가능한 개선
1. **클래스 취약점 분석** 실행:
```bash
python -m src.analysis.class_performance_analyzer run_comprehensive_analysis \
    --predictions_csv outputs/predictions/predictions_latest.csv
```

2. **보수적 증강 테스트** 실행:
```bash
python -m src.training.conservative_augmentation_tester run_conservative_augmentation_test \
    --baseline_checkpoint outputs/models/best_model.pth
```

3. **점진적 데이터셋 생성**:
```bash
python scripts/generate_datasets.py generate_progressive --multiplier=10
```

