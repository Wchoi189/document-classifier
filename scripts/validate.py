# scripts/debug_dataset_paths.py
"""
Debug script to check K-fold dataset structure and paths
K-fold ë°ì´í„°ì…‹ êµ¬ì¡°ì™€ ê²½ë¡œ í™•ì¸ìš© ë””ë²„ê·¸ ìŠ¤í¬ë¦½íŠ¸
"""

import pandas as pd
from pathlib import Path
from icecream import ic
import fire


class DatasetPathDebugger:
    """ë°ì´í„°ì…‹ ê²½ë¡œ êµ¬ì¡° ë””ë²„ê¹…"""
    
    def check_phase1_structure(self):
        """Phase 1 ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸"""
        ic("ğŸ” Phase 1 ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸")
        
        base_path = Path("data/augmented_datasets/phase1_mild_fold_0")
        
        # ê¸°ë³¸ êµ¬ì¡° í™•ì¸
        ic(f"ê¸°ë³¸ ê²½ë¡œ ì¡´ì¬: {base_path.exists()}")
        
        if base_path.exists():
            ic("ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°:")
            for item in base_path.iterdir():
                ic(f"  {item.name} ({'dir' if item.is_dir() else 'file'})")
        
        # Train ë””ë ‰í† ë¦¬ í™•ì¸
        train_dir = base_path / "train"
        ic(f"Train ë””ë ‰í† ë¦¬ ì¡´ì¬: {train_dir.exists()}")
        
        if train_dir.exists():
            train_files = list(train_dir.glob("*.jpg"))
            ic(f"Train ì´ë¯¸ì§€ ìˆ˜: {len(train_files)}")
            if train_files:
                ic(f"ì²« ë²ˆì§¸ íŒŒì¼: {train_files[0].name}")
                ic(f"ë§ˆì§€ë§‰ íŒŒì¼: {train_files[-1].name}")
        
        # Val ë””ë ‰í† ë¦¬ í™•ì¸
        val_dir = base_path / "val"
        ic(f"Val ë””ë ‰í† ë¦¬ ì¡´ì¬: {val_dir.exists()}")
        
        if val_dir.exists():
            val_files = list(val_dir.glob("*.jpg"))
            ic(f"Val ì´ë¯¸ì§€ ìˆ˜: {len(val_files)}")
            if val_files:
                ic(f"ì²« ë²ˆì§¸ íŒŒì¼: {val_files[0].name}")
        
        # CSV íŒŒì¼ í™•ì¸
        metadata_dir = base_path / "metadata"
        if metadata_dir.exists():
            train_csv = metadata_dir / "train.csv"
            val_csv = metadata_dir / "val.csv"
            
            if train_csv.exists():
                train_df = pd.read_csv(train_csv)
                ic(f"Train CSV í–‰ ìˆ˜: {len(train_df)}")
                ic(f"Train CSV ìƒ˜í”Œ: {train_df['ID'].head(3).tolist()}")
            
            if val_csv.exists():
                val_df = pd.read_csv(val_csv)
                ic(f"Val CSV í–‰ ìˆ˜: {len(val_df)}")
                ic(f"Val CSV ìƒ˜í”Œ: {val_df['ID'].head(3).tolist()}")
    
    def check_phase2_structure(self):
        """Phase 2 ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸"""
        ic("ğŸ” Phase 2 ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸")
        
        base_path = Path("data/augmented_datasets/phase2_variety_fold_0")
        
        # ê¸°ë³¸ êµ¬ì¡° í™•ì¸
        ic(f"ê¸°ë³¸ ê²½ë¡œ ì¡´ì¬: {base_path.exists()}")
        
        if base_path.exists():
            ic("ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°:")
            for item in base_path.iterdir():
                ic(f"  {item.name} ({'dir' if item.is_dir() else 'file'})")
        
        # Val ë””ë ‰í† ë¦¬ í™•ì¸ (cross-phase validationìš©)
        val_dir = base_path / "val"
        ic(f"Val ë””ë ‰í† ë¦¬ ì¡´ì¬: {val_dir.exists()}")
        
        if val_dir.exists():
            val_files = list(val_dir.glob("*.jpg"))
            ic(f"Val ì´ë¯¸ì§€ ìˆ˜: {len(val_files)}")
            if val_files:
                ic(f"ì²« ë²ˆì§¸ íŒŒì¼: {val_files[0].name}")
                ic(f"ë§ˆì§€ë§‰ íŒŒì¼: {val_files[-1].name}")
        
        # CSV íŒŒì¼ í™•ì¸
        metadata_dir = base_path / "metadata"
        if metadata_dir.exists():
            val_csv = metadata_dir / "val.csv"
            
            if val_csv.exists():
                val_df = pd.read_csv(val_csv)
                ic(f"Phase 2 Val CSV í–‰ ìˆ˜: {len(val_df)}")
                ic(f"Phase 2 Val CSV ìƒ˜í”Œ: {val_df['ID'].head(3).tolist()}")
    
    def check_file_mapping(self):
        """CSVì™€ ì‹¤ì œ íŒŒì¼ ë§¤í•‘ í™•ì¸"""
        ic("ğŸ” CSVì™€ ì‹¤ì œ íŒŒì¼ ë§¤í•‘ í™•ì¸")
        
        # Phase 1 Train í™•ì¸
        train_csv_path = Path("data/augmented_datasets/phase1_mild_fold_0/metadata/train.csv")
        train_dir = Path("data/augmented_datasets/phase1_mild_fold_0/train")
        
        if train_csv_path.exists() and train_dir.exists():
            train_df = pd.read_csv(train_csv_path)
            sample_files = train_df['ID'].head(5).tolist()
            
            ic("Phase 1 Train íŒŒì¼ ì¡´ì¬ í™•ì¸:")
            for filename in sample_files:
                file_path = train_dir / filename
                ic(f"  {filename}: {'âœ…' if file_path.exists() else 'âŒ'} ({file_path})")
        
        # Phase 2 Val í™•ì¸
        val_csv_path = Path("data/augmented_datasets/phase2_variety_fold_0/metadata/val.csv")
        val_dir = Path("data/augmented_datasets/phase2_variety_fold_0/val")
        
        if val_csv_path.exists() and val_dir.exists():
            val_df = pd.read_csv(val_csv_path)
            sample_files = val_df['ID'].head(5).tolist()
            
            ic("Phase 2 Val íŒŒì¼ ì¡´ì¬ í™•ì¸:")
            for filename in sample_files:
                file_path = val_dir / filename
                ic(f"  {filename}: {'âœ…' if file_path.exists() else 'âŒ'} ({file_path})")
    
    def suggest_fix(self):
        """ê²½ë¡œ ë¬¸ì œ í•´ê²° ë°©ì•ˆ ì œì‹œ"""
        ic("ğŸ’¡ ê²½ë¡œ ë¬¸ì œ í•´ê²° ë°©ì•ˆ")
        
        # ì‹¤ì œ êµ¬ì¡° íŒŒì•…
        self.check_phase1_structure()
        self.check_phase2_structure()
        self.check_file_mapping()
        
        ic("ğŸ”§ ê°€ëŠ¥í•œ í•´ê²°ì±…:")
        ic("1. ì´ë¯¸ì§€ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìˆëŠ”ì§€ í™•ì¸")
        ic("2. CSV íŒŒì¼ì˜ ID ì»¬ëŸ¼ê³¼ ì‹¤ì œ íŒŒì¼ëª… ì¼ì¹˜ í™•ì¸")
        ic("3. Dataset loaderì˜ ê²½ë¡œ êµ¬ì„± ë¡œì§ ìˆ˜ì •")


def main():
    fire.Fire(DatasetPathDebugger)


if __name__ == "__main__":
    main()