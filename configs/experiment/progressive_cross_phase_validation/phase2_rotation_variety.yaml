# @package _global_
defaults:
  - _self_

name: "phase2-rotation-variety-double-data-2-7-3-class"
description: "Phase 2: Rotation variety (±60° + 90°) - Progressive training"
tags: ["progressive", "phase2", "rotation", "reduced lr and weight decay","cross-phase-validation","double data 2,7 class"]

seed: 42
device: 'cuda'

# Phase 2 dataset
data:
  root_dir: "data/augmented_datasets/phase2_variety_fold_0"
  csv_file: "data/augmented_datasets/phase2_variety_fold_0/metadata/train.csv"
  meta_file: "data/augmented_datasets/phase2_variety_fold_0/metadata/meta.csv"

  # Validate on Phase 3 data (harder conditions)
  val_root_dir: "data/augmented_datasets/phase3_full_fold_0"
  val_csv_file: "data/augmented_datasets/phase3_full_fold_0/metadata/val.csv"


  image_size: 224
  val_size: 0.0
  num_workers: 4
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]

augmentation:
  enabled: false
  strategy: "basic"
  # intensity: 0.0

model:
  name: "resnet50"
  pretrained: false  # Will load from Phase 1

train:
  epochs: 40  # ~40% of total 50 epochs
  batch_size: 32
  mixed_precision: false
  
  # Phase transition settings
  load_checkpoint: "outputs/progressive/outputs/progressive/phase1/last_model.pth"
  
  early_stopping:
    patience: 5
    metric: 'val_loss'
    mode: 'min'

## Experiment settings    
# original (overfit at epoch 4)
# optimizer:
#   name: 'AdamW'
#   learning_rate: 0.0001  # Reduced for fine-tuning
#   weight_decay: 0.0001

# scheduler:
#   name: 'CosineAnnealingWarmRestarts'
#   T_0: 10
#   T_mult: 2
#   eta_min: 0.00001

# mitigation attempt

optimizer:
  name: 'AdamW'
  learning_rate: 0.00005  # Reduce from 0.0001 to 0.00005
  weight_decay: 0.001     # Increase from 0.0001 for more regularization

scheduler:
  name: 'CosineAnnealingWarmRestarts'
  T_0: 8
  T_mult: 2
  eta_min: 0.000005  # Reduce from 0.00001 (should be ~10% of initial LR)

wandb:
  enabled: true
  project: "document-classifier"
  name: "phase2-variety-rotation-60deg-double_data_2_7_3_class"
  tags: ["progressive", "phase2", "rotation-60deg"]
  notes: "Phase 2: Variety training ±60° + discrete 90°, no augmentation"
  username: wchoi189

  log_frequency: 10
  log_images: true
  log_model: false
  log_gradients: false
  log_confusion_matrix: true
  watch_model: true
  log_code: true

paths:
  output_dir: "outputs/progressive/lr_decay_mitigation/double_data_2_7_3_class"
  model_dir: "outputs/progressive/phase2/lr_decay_mitigation/double_data_2_7_3_class"

logging:
  checkpoint_dir: "outputs/progressive/phase2/lr_decay_mitigation/double_data_2_7_3_class"